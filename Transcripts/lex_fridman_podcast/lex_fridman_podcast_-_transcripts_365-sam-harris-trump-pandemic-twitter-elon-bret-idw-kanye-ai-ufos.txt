Disclaimer: The transcript that follows has been generated using artificial intelligence. We strive to be as accurate as possible, but minor errors and slightly off timestamps may be present.
You can click the timestamp to jump to that time.
Lex Fridman (00:00):
The following is a conversation with Sam Harris, his second time on the podcast. As I said two years ago, when I first met and spoke with Sam, he’s one of the most influential pioneering thinkers of our time, as the host of the Making Sense podcast, creator of the Waking Up app, and the author of many seminal books on human nature and the human mind, including The End of Faith, The Moral Landscape, Lying, Free Will, and Waking Up.
(00:28):
In this conversation, besides our mutual fascination with AGI and free will, we do also go deep into controversial, challenging topics of Donald Trump, Hunter Biden, January 6th, vaccines, lab leak, Kanye West, and several key figures at the center of public discourse, including Joe Rogan and Elon Musk, both of whom have been friends of Sam and have become friends of mine. Somehow, in an amazing life trajectory that I do not deserve in any way, and in fact believe is probably a figment of my imagination. And if it’s all right, please allow me to say a few words about this personal aspect of the conversation, of discussing Joe, Elon, and others. What’s been weighing heavy on my heart since the beginning of the pandemic, now three years ago, is that many people I look to for wisdom in public discourse, have not been able to find in public discourse, stop talking to each other as often, with respect, humility, and love, when the world needed those kinds of conversations the most.
(01:30):
My hope is that they start talking again, they start being friends again, they start noticing the humanity that connects them, that is much deeper than the disagreements that divide them. So let me take this moment to say, with humility and honesty, why I look up to and I’m inspired by Joe, Elon, and Sam. I think Joe Rogan is important to the world, as a voice of compassionate curiosity and open-mindedness to ideas, both radical and mainstream, sometimes with humor, sometimes with brutal honesty, always pushing for more kindness in the world.
(02:06):
I think Elon Musk is important to the world, as an engineer, leader, entrepreneur, and human being who takes on the hardest problems that face humanity and refuses to accept the constraints of conventional thinking that made the solutions to these problems seem impossible. I think Sam Harris is important to the world, as a fearless voice who fights for the pursuit of truth against growing forces of echo chambers and audience capture, taking unpopular perspectives and defending them with rigor and resilience.
(02:39):
I both celebrate and criticize all three privately, and they criticize me, usually more effectively, from which I always learn a lot and always appreciate. Most importantly, there is respect and love for each other as human beings, the very thing that I think the world needs most now in a time of division and chaos.
(02:59):
I will continue to try to mend divisions, to try to understand, not deride, to turn the other cheek if needed, to return hate with love. Sometimes people criticize me for being naive, cheesy, simplistic, all that. I know, I agree, but I really am speaking from the heart and I’m trying. This world is too fucking beautiful not to try in whatever way I know how. I love you all.
(03:30):
And now, a quick few second mention of each sponsor. Check them out in the description. It’s the best way to support this podcast. We got Notion for AI-powered note-taking and team collaboration, Indeed for hiring great teams, and the Masterclass for online learning. Choose wisely, my friends. Also, if you want to work with our team, we’re always hiring, go to lexfriedman.com slash hiring. And now, onto the full ad reads. As always, no ads in the middle. I try to make this interesting, but if you must skip them, please still check out our sponsors. I enjoy their stuff. Maybe you will, too.
(04:06):
This show is brought to you by Notion, a note-taking and team collaboration tool, my favorite note-taking and team collaboration tool. And they have a new feature, Notion AI, that I’ve been using and loving, and this thing is probably the best implementation of a system that uses a language model to generate text. Because it integrates across the entirety of your note-taking process, and it adds just a giant number of small and big features that help you out, that save a lot of time, but also make everything more fun, and creatively sort of inject ideas into your workflow. So just to list some features, they can edit the voice and tone of the text you already wrote, so they can rewrite it in a different tone. They can make the text, which I love, they can make it shorter or longer. Also, they can simplify the text, which to me is at the core of the writing process.
(05:10):
Make things as simple as possible, but not simpler, as Einstein said. And to have tools that give you ideas how to do that, not necessarily completely automate everything, but give you really powerful ideas of how to get 90% there, this is just brilliant. Also, if there’s technical jargon, they can rewrite the text and explain it more simply. What else? They can obviously summarize the text. If you start writing, they can continue your writing.
(05:37):
If you’re having trouble starting to write and there’s a blank page glaring back at you, they can generate, based on a topic, a bunch of text to get you going. I mean, there’s so many just amazing features. I love it when great, powerful language models or any idea in AI is then injected into a tool that’s actually usable and useful and powerful across a number of use cases to a huge number of people. I mean, this is really, really, really exciting. Notion AI helps you work faster, write better and think bigger, doing tasks that normally take you hours and just minutes. Try Notion AI for free when you go to notion.com slash lex. That’s all lowercase, notion.com slash lex to try the power of Notion AI today.
(06:26):
This show is also brought to you by Indeed, a hiring website. I’ve used it, I continue to use it to hire folks for the teams I’ve been on, I’ve led from engineering to creative. Everything requires a rigorous, systematic, artistic, all many adjectives I want to use process to build up an amazing team because there’s nothing more important to the success of an endeavor or the success of life or to just your contentment and happiness and joy and fulfillment and a source of meaning than the team that you take on the hard challenges of life with, of work with. So you should use the best tools for the job of hiring and you should take hiring very, very, very seriously. Don’t overspend on hiring. Visit indeed.com slash lex to start hiring now. That’s indeed.com slash lex. Terms and conditions apply.
(07:31):
This show is also brought to you by Masterclass. $180 a year, gets you an all-access pass to watch courses from the best people in the world in their respective disciplines. One of the people I just recently talked to is Chris Voss. He is a former FBI hostage negotiator. Brilliant guy. Off the mic, I really enjoy talking to him. There is kindness, camaraderie, thoughtfulness, humor, wit, also a certain sort of cultural density and complexity, hailing from New York or whatever that rich, sexy accent is from. It’s just really fun to listen to him, to listen to him discuss what he’s really good at. That was true on the podcast and that is very much true in his Masterclass where he really systematically breaks down his ideas of what it takes to negotiate with terrorists, negotiate with hostage takers, negotiate with bank robbers, but I think the most important thing is negotiate in everyday life.
(08:34):
To negotiate in business relationships, all of that. It’s just a really brilliant, concise, clear, actionable advice that he gives. And that’s true for almost every single Masterclass they have and you get access to all of them. Get unlimited access to every Masterclass and get 15% off an annual membership at masterclass.com slash Lex.
(09:00):
This is the Lex Friedman Podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Sam Harris. What is more effective at making a net positive impact on the world, empathy or reason?
Sam Harris (09:31):
It depends on what you mean by empathy. There are at least two kinds of empathy. There’s the cognitive form, which is, I would argue, even a species of reason. It’s just understanding another person’s point of view. You understand why they’re suffering or why they’re happy or what, you know. Just, you have a theory of mind about another human being that is accurate. And so you can navigate in relationship to them more effectively.
(10:06):
And then there’s another layer entirely, not incompatible with that, but just distinct, which is what people often mean by empathy, which is more a kind of emotional contagion, right? Like you feel depressed and I begin to feel depressed along with you because, you know, it’s just, it’s contagious, right? You know, we’re so close and I’m so concerned about you and your problems become my problems and it bleeds through, right? Now, I think both of those capacities are very important, but the emotional contagion piece, and this is not really my thesis, this is something I have more or less learned from Paul Bloom, the psychologist who wrote a book on this topic titled Against Empathy. The emotional social contagion piece is a bad guide rather often for ethical behavior and ethical intuitions. Oh boy. And I will give you the clear example of this, which is, we find stories with a single identifiable protagonist a single identifiable protagonist who we can effortlessly empathize with far more compelling than data, right? So if I tell you, you know, this is the classic case of the little girl who falls down a well, right? You know, this is somebody’s daughter. You see the parents distraught on television.
(11:40):
You hear her cries from the bottom of the well. The whole country stops. I mean, there was an example of this 20, 25 years ago, I think, where it was just wall to wall on CNN. This is just the perfect use of CNN. It was, you know, 72 hours, whatever it was of continuous coverage of just extracting this girl from a well. So we effortlessly pay attention to that. We care about it. We will donate money toward it. I mean, it’s just, it marshals 100% of our compassion and altruistic impulse.
(12:10):
Whereas if you hear that there’s a genocide raging in some country you’ve never been to and never intended to go to, and the numbers don’t make a dent, and we find the story boring, right? And we’ll change the channel in the face of a genocide, right? It doesn’t matter. And it literally, perversely, it could be 500,000 little girls have fallen down wells in that country, and we still don’t care, right? So it’s, you know, many of us have come to believe that this is a bug rather than a feature of our moral psychology. And so empathy plays an unhelpful role there. So ultimately I think when we’re making big decisions about what we should do and how to mitigate human suffering and what’s worth valuing and how we should protect those values, I think reason is the better tool. But it’s not that I would want to dispense with any part of empathy either.
Lex Fridman (13:03):
Well, there’s a lot of changes to go on there. But briefly to mention, you’ve recently talked about effective altruism on your podcast. I think you mentioned some interesting statement. I’m going to horribly misquote you. But that you’d rather live in a world, like it doesn’t really make sense, but you’d rather live in a world where you care about maybe your daughter and son more than a hundred people that live across the world, something like this. Like where the calculus is not always perfect, but somehow it makes sense to live in a world where it’s irrational in this way and yet empathetic in the way you’ve been discussing.
Sam Harris (13:41):
Right, I’m not sure what the right answer is there or even whether there is one right answer. There could be multiple peaks on this part of the moral landscape. So the opposition is between an ethic that’s articulated by someone like the Dalai Lama, right? Or really any exponent of classic Buddhism would say that the ultimate enlightened ethic is true dispassion with respect to friends and strangers, right? So that you would, the mind of the Buddha would be truly dispassionate. You would love and care about all people equally.
(14:19):
And by that light, it seems some kind of ethical failing or at least a failure to fully actualize compassion in the limit or enlightened wisdom in the limit to care more or even much more about your kids than the kids of other people and to prioritize your energy in that way, right? So you spend all this time trying to figure out how to keep your kids healthy and happy and you’ll attend to their minutest concerns and however superficial. And again, there’s a genocide raging in Sudan or wherever and it takes up less than 1% of your bandwidth.
(14:60):
I’m not sure it would be a better world if everyone was running the Dalai Lama program there. I think some prioritization of one’s nearest and dearest ethically might be optimal because we’ll all be doing that and we’ll all be doing that in a circumstance where we have certain norms and laws and other structures that force us to be dispassionate where that matters, right?
(15:33):
So when I go to, when my daughter gets sick and I have to take her to a hospital, I really want her to get attention, right? And I’m worried about her more than I’m worried about everyone else in the lobby. But the truth is I actually don’t want a totally corrupt hospital. I don’t want a hospital that treats my daughter better than anyone else in the lobby because she’s my daughter and I’ve bribed the guy at the door or whatever, the guy’s a fan of my podcast or whatever the thing is. You don’t want starkly corrupt, unfair situations. And when you sort of get pressed down the hierarchy of Maslow’s needs, individually and societally, a bunch of those variables change and they change for the worse, understandably. But yeah, when everyone’s corrupt and you’re in a state of collective emergency, you’ve got a lifeboat problem, you’re scrambling to get into the lifeboat.
(16:31):
Yeah, then fairness and norms and the other vestiges of civilization begin to get stripped off. We can’t reason from those emergencies to normal life. I mean, in normal life, we want justice, we want fairness, we’re all better off for it even when the spotlight of our concern is focused on the people we know, the people who are friends, the people who are family, people we have good reason to care about. We still, by default, want a system that protects the interests of strangers too. And we know that generally speaking, just in game theoretic terms, we’re all gonna tend to be better off in a fair system than a corrupt one.
Lex Fridman (17:17):
One of the failure modes of empathy is our susceptibility to anecdotal data. Just a good story will get us to not think clearly. But what about empathy in the context of just discussing ideas with other people? And then there’s a large number of people, like in this country, you know, red and blue, half the population believes certain things on immigration or on the response to the pandemic or any kind of controversial issue, even if the election was fairly executed.
(17:53):
Having an empathy for their worldview, trying to understand where they’re coming from, not just in the explicit statement of their idea, but the entirety of like the roots from which their idea stems, that kind of empathy while you’re discussing ideas. What is, in your pursuit of truth, having empathy for the perspective of a large number of other people versus raw mathematical reason?
Sam Harris (18:20):
I think it’s important, but it only takes you so far, right? It doesn’t get you to truth, right? It’s not, truth is not a, the truth is not a, it’s not decided by, you know, democratic principles. And certain people believe things for understandable reasons, but those reasons are nonetheless bad reasons, right? They don’t scale, they don’t generalize, they’re not reasons anyone should adopt for themselves or respect, you know, epistemologically. And yet their circumstance is understandable and it’s something you can care about, right? And so, yeah, like, let me just take, I think there’s many examples of this that you might be thinking of, but I mean, one that comes to mind is I’ve been super critical of Trump, obviously, and I’ve been super critical of certain people for endorsing him or not criticizing him when he really made it, you know, patently obvious who he was, you know, if there had been any doubt initially. There was no doubt when we have a sitting president who’s not agreeing to a peaceful transfer of power, right? So I’m critical of all of that, and yet the fact that many millions of Americans didn’t see what was wrong with Trump or bought into the, didn’t see through his con, right? I mean, they bought into the idea that he was a brilliant businessman who might just be able to change things because he’s so unconventional and so, you know, his heart is in the right place. You know, he’s really a man of the people, even though he’s, you know, gold-plated everything in his life. They bought the myth somehow of, you know, largely because they had seen him on television for almost a decade and a half pretending to be this genius businessman who could get things done. It’s understandable to me that many very frustrated people who have not had their hopes and dreams actualized, who have been the victims of globalism and many other, you know, current trends, it’s understandable that they would be confused and not see the liability of electing a grossly incompetent, morbidly narcissistic person into the presidency.
(20:55):
So which is to say that I don’t blame, there are many, many millions of people who I don’t necessarily blame for the Trump phenomenon, but I can nonetheless bemoan the phenomenon as indicative of, you know, a very bad state of affairs in our society, right? So there’s two levels to it. I mean, one is, I think you have to call a spade a spade when you’re talking about how things actually work and what things are likely to happen or not, but then you can recognize that people have very different life experiences, and yeah, I mean, I think empathy, and you know, probably the better word for what I would hope to embody there is compassion, right? Like really, you know, to really wish people well, you know, and to really wish, you know, strangers well, effortlessly wish them well. I mean, to realize that there is no opposition between, at bottom, there’s no real opposition between selfishness and selflessness, because why is selfishness really takes into account other people’s happiness? I mean, you know, do you want to live in a society where you have everything, but most other people have nothing? Or do you want to live in a society where you’re surrounded by happy, creative, self-actualized people who are having their hopes and dreams realized? I think it’s obvious that the second society is much better, however much you can guard your good luck.
Lex Fridman (22:22):
But what about having empathy for certain principles that people believe? For example, the pushback, the other perspective on this, because you said bought the myth of Trump as the great businessman. There could be a lot of people that are supporters of Trump who could say that Sam Harris bought the myth that we have this government of the people, by the people, that actually represents the people, as opposed to a bunch of elites who are running a giant bureaucracy that is corrupt, that is feeding themselves, and they’re actually not representing the people. And then here’s this chaos agent, Trump, who speaks off the top of his head. Yeah, he’s flawed in all this number of ways. He’s a more comedian than he is a presidential type of figure. And he’s actually creating the kind of chaos that’s going to shake up this bureaucracy, shake up the elites that are so uncomfortable because they don’t want the world to know about the game they’ve got running on everybody else. So that’s the kind of perspective that they would take and say, yeah, yeah, there’s these flaws that Trump has, but this is necessary.
Sam Harris (23:32):
I agree with the first part. So I haven’t bought the myth that it’s a truly representative democracy in the way that we might idealize. And on some level, I mean, this is a different conversation, but on some level, I’m not even sure how much I think it should be. I’m not sure we want, in the end, everyone’s opinion given equal weight about just what we should do about anything. And I include myself in that. I mean, there are many topics around which I don’t deserve to have a strong opinion because I don’t know what I’m talking about, right, or what I would be talking about if I had a strong opinion.
(24:17):
And I think we’ll probably get to that, to some of those topics, because I’ve declined to have certain conversations on my podcast just because I think I’m the wrong person to have that conversation, right? And I think it’s important to see those bright lines in one’s life and in the moment, politically and ethically. So yeah, I think, so leave aside the viability of democracy. I’m under no illusions that all of our institutions are worth preserving precisely as they have been up until the moment this great orange wrecking ball came swinging through our lives.
(24:59):
I just, it was a very bad bet to elect someone who is grossly incompetent, and worse than incompetent, genuinely malevolent in his selfishness, right? And this is something we know based on literally decades of him being in the public eye. He’s not a public servant in any normal sense of that term. And he couldn’t possibly give an honest or sane answer to the question you asked me about empathy and reason and what should guide us.
(25:39):
I genuinely think he is missing some necessary moral and psychological tools, right? And this is, I can feel compassion for him as a human being because I think having those things is incredibly important and genuinely loving other people is incredibly important. And knowing what all it’s about is that’s really the good stuff in life. And I think he’s missing a lot of that. But I think we don’t wanna promote people to the highest positions of power in our society who are far outliers in pathological terms, right?
(26:15):
We want them to be far outliers in the best case, in wisdom and compassion and some of the topics you’ve brought up. I mean, we want someone to be deeply informed. We want someone to be unusually curious, unusually alert to how they may be wrong or getting things wrong consequentially. He’s none of those things. And insofar as we’re gonna get normal mediocrities in that role, which I think is often the best we could expect, let’s get normal mediocrities in that role, not once in a generation narcissists and frauds. I mean, it’s like we just take honesty as a single variable, right? I think you want, yes, it’s possible that most politicians lie at least some of the time. I don’t think that’s a good thing. I think people should be generally honest, even to a fault. Yes, there are certain circumstances where lying I think is necessary. It’s kind of on a continuum of self-defense and violence. So it’s like if the Nazis come to your door and ask you if you’ve got Anne Frank in the attic, I think it’s okay to lie to them. But Trump, arguably there’s never been a person that anyone could name in human history who’s lied with that kind of velocity. I mean, it’s just, he was just a blizzard of lies, great and small, to pointless and effective, but it’s just, it says something fairly alarming about our society that a person of that character got promoted. And so, yes, I have compassion and concern for half of the society who didn’t see it that way, and that’s gonna sound elitist and smug or something for anyone who’s on that side listening to me, but it’s genuine. I mean, I understand that, like, I barely have the, I’m like one of the luckiest people in the world, and I barely have the bandwidth to pay attention to half the things I should pay attention to in order to have an opinion about half the things we’re gonna talk about, right? So how much less bandwidth does somebody who’s working two jobs or a single mom who’s raising multiple kids, even a single kid? It’s just, it’s unimaginable to me that people have the bandwidth to really track this stuff, and so then they jump on social media and they get inundated by misinformation and they see what their favorite influencer just said, and now they’re worried about vaccines, and it’s just, we’re living in an environment where the information space has become so corrupted, and we’ve built machines to further corrupt it. I mean, we’ve built a business model for the internet that it further corrupts it.
(29:23):
So it is just, it’s chaos in informational terms, and I don’t fault people for being confused and impatient and at their wit’s end, and yes, Trump was an enormous fuck you to the establishment, and that was understandable
Lex Fridman (29:47):
for many reasons. To me, Sam Harris, the great Sam Harris is somebody I’ve looked up to for a long time as a beacon of voice of reason, and there’s this meme on the internet, and I would love you to steel man the case for it and against, that Trump broke Sam Harris’s brain, that there’s something is disproportionately to the actual impact that Trump had on our society.
(30:13):
He had an impact on the ability of balanced, calm, rational minds to see the world clearly, to think clearly, you being one of the beacons of that. Is there a degree to which he broke your brain? Otherwise known as Trump derangement syndrome, medically.
Sam Harris (30:35):
Yeah, I think Trump derangement syndrome is a very clever meme because it just throws the problem back on the person who’s criticizing Trump, but in truth, the true Trump derangement syndrome was not to have seen how dangerous and divisive it would be to promote someone like Trump to that position of power, and in the final moment, not to see how untenable it was to still support someone who, a sitting president who was not committing to a peaceful transfer of power. I mean, if that wasn’t a bright line for you, you have been deranged by something, because that was one minute to midnight for our democracy, as far as I’m concerned, and I think it really was, but for the integrity of a few people that we didn’t suffer some real constitutional crisis and real emergency after January 6th. I mean, if Mike Pence had caved in and decided to not certify the election, right?
(31:48):
Literally, you can count on two hands the number of people who held things together at that moment, and so it wasn’t for want of trying on Trump’s part that we didn’t succumb to some real, truly uncharted catastrophe with our democracy. So the fact that that didn’t happen is not a sign that those of us who were worried that it was so close to happening were exaggerating the problem. I mean, it’s like you almost got run over by a car, but you didn’t, and so the fact that you’re adrenalized and you’re thinking, boy, that was dangerous, I probably shouldn’t wander in the middle of the street with my eyes closed, you weren’t wrong to feel that you really had a problem, right, and came very close to something truly terrible. So I think that’s where we were, and I think we shouldn’t do that again, right? So the fact that he’s still, he’s coming back around as potentially a viable candidate, I’m not spending much time thinking about it, frankly, because I’m waiting for the moment where it requires some thought. I mean, it took up, I mean, I don’t know how many podcasts I devoted to the topic. It wasn’t that, I mean, it wasn’t that many in the end against the number of podcasts I devoted to other topics, but there are people who look at Trump and just find him funny, entertaining, not especially threatening. He’s like not a, you know, it’s just good fun to see somebody who’s just not taking anything seriously, and is just putting a stick in the wheel of business as usual again and again and again and again.
(33:39):
And they don’t really see anything much at stake, right? It doesn’t really matter if we don’t support NATO. It doesn’t really matter if he says he trusts Putin more than our intelligence services. I mean, none of this, it doesn’t matter if he’s, on the one hand, saying that he loves the leader of North Korea, and on the other, threatening, threatens to, you know, bomb them back to the Stone Age, right, on Twitter. It’s all, it all can be taken in the spirit of kind of reality television. It’s like, this is just, this is the part of the movie that’s just fun to watch, right? And I understand that. I can even inhabit that space for a few minutes at a time, but there’s a deeper concern that we’re in the process of entertaining ourselves to death, right, that we’re just not taking things seriously. And this is a problem I’ve had with several other people we might name, who just appear to me to be goofing around at scale, and they lack a kind of moral seriousness. I mean, they’re touching big problems where lives hang in the balance, but they’re just fucking around.
(34:47):
And I think they’re really important problems that we have to get our head straight around. And we need, you know, it’s not to say that institutions don’t become corrupt. I think they do, and I think, and I’m quite worried that, you know, both about the loss of trust in our institutions and the fact that trust has eroded for good reason, right, that they have become less trustworthy. I think, you know, they’ve become infected by, you know, political ideologies that are not truth-tracking. I mean, I worry about all of that, but I just think we need institutions. We need to rebuild them. We need experts who are real experts. We need to value expertise over, you know, amateurish speculation and conspiracy thinking, and just, you know, and bullshit.
Lex Fridman (35:35):
The kind of amateur speculation we’re doing on this very podcast.
Sam Harris (35:41):
I’m usually alert to the moments where I’m just guessing or where I actually feel like I’m talking from within my wheelhouse, and I try to telegraph that a fair amount with people. So yeah, I mean, but it’s not, it’s different.
(35:59):
Like, I mean, you can invite someone onto your podcast who’s an expert about something that you’re not an expert about, and then you, you, in the process of getting more informed yourself, your audience is getting more informed, so you’re asking smart questions, and you might be pushing back at the margins, but you know that when push comes to shove on that topic, you really don’t have a basis to have a strong opinion, and if you were gonna form a strong opinion that was this counter to the expert you have in front of you, it’s gonna be by deference to some other expert who you’ve brought in or who you’ve heard about or whose work you’ve read or whatever. But there’s a paradox to how we value authority in science that most people don’t understand, and I think we should, at some point, unravel that, because it’s the basis for a lot of public confusion, and frankly, it’s the basis for a lot of criticism I’ve received on these topics, where people think that I’m against free speech or I’m an establishment shill, or it’s like I just think, I’m a credentialist, I just think people with PhDs from Ivy League universities should run everything.
(37:15):
It’s not true, but there’s a ton of, there’s a lot to cut through to get to daylight there, because people are very confused about how we value authority. In the service of rationality, generally.
Lex Fridman (37:29):
You’ve talked about it, but it’s just interesting, the intensity of feeling you have. You’ve had this famous phrase about Hunter Biden and children in the basement. Can you just revisit this case? So let me give another perspective on the situation of January 6th and Trump in general. It’s possible that January 6th and things of that nature revealed that our democracy is actually pretty fragile, and that Trump is not a malevolent, an ultra-competent malevolent figure, but is simply a jokester, and he just, by creating the chaos, revealed that it’s all pretty fragile, because you’re a student of history, and there’s a lot of people, like Vladimir Lenin, Hitler, who are exceptionally competent at controlling power, at being executives and taking that power, controlling the generals, controlling all the figures involved, and certainly not tweeting, but working in the shadows, behind the scenes, to gain power.
(38:33):
And they did so extremely competently, and that is how they were able to gain power. The pushback with Trump, he was doing none of that. He was creating, which he’s very good at, creating drama, sometimes for humor’s sake, sometimes for drama’s sake, and simply revealed that our democracy is fragile. And so he’s not this once-in-a-generation horrible figure.
Sam Harris (38:58):
Once-in-a-generation narcissist. No, I don’t think he’s a truly scary, sinister, scary, sinister, Putin-like, or Hitler, much less Hitler-like figure, not at all. I mean, he’s not ideological. He doesn’t care about anything beyond himself. So it’s not… No, no, he’s much less scary than any really scary totalitarian, right? I mean, and he’s… He’s more brave in your world than 1984.
(39:29):
This is what Eric Weinstein never stops badgering me about, but he’s still wrong, Eric. My analogy for Trump was that he’s an evil Chauncey Gardner. I don’t know if you remember the book or the film, Being There, with Peter Sellers. But Peter Sellers is this gardener who really doesn’t know anything, but he gets recognized as this wise man and he gets promoted to immense power in Washington because he’s speaking in a semblance of wisdom.
(40:02):
He’s got these very simple aphorisms or what seem to be aphorisms. All he cares about is gardening. He’s just talking about his garden all the time, but he’ll say something. But yeah, in the spring, the new shoots will bloom, and people read into that some kind of genius insight politically, and so he gets promoted. So that’s the joke of the film.
(40:25):
For me, Trump has always been someone like an evil Chauncey Gardner. He’s, it’s not to say he’s totally, yes, he has a certain kind of genius. He’s got a genius for creating a spectacle around himself. He’s got a genius for getting the eye of the media always coming back to him. But it’s only, it’s a kind of, it’s a kind of self-promotion that only works if you actually are truly shameless and don’t care about having a reputation for anything that I or you would want to have a reputation for, right? It’s like it’s pure, the pure pornography of attention, right, and he just wants more of it. I think the truly depressing and genuinely scary thing was that we have a country, at least half of the country, half of the country, given how broken our society is in many ways, we have a country that didn’t see anything wrong with that, bringing someone who obviously doesn’t know what he should know to be president and who’s obviously not a good person, right, obviously doesn’t care about people, can’t even pretend to care about people really, right, in a credible way, and so, I mean, if there’s a silver lining to this, it’s along the lines you just sketched, it shows us how vulnerable our system is to a truly brilliant and sinister figure, right? I mean, like, I think we are, we really dodged a bullet. Yeah, someone far more competent and conniving and ideological could have exploited our system in a way that Trump didn’t, and that’s, yeah, so if we plug those holes eventually, that would be a good thing, and he would have done a good thing for our society, right? I mean, one of the things we realized, and I think nobody knew, I mean, I certainly didn’t know it and I didn’t hear anyone talk about it, is how much our system relies on norms rather than laws. Yeah, civility almost. Yeah, it’s just like it’s, it’s quite possible that he never did anything illegal, you know, truly illegal. I mean, I think he probably did a few illegal things, but like illegal such that he really should be thrown in jail for it, you know? At least that remains to be seen.
(42:56):
So all of the chaos, all of the, you know, all of the diminishment of our stature in the world, all of the, just the opportunity costs of spending years focused on nonsense, all of that was just norm violations. All that was just, that was just all a matter of not saying the thing you should say, but that doesn’t mean they’re insignificant, right? It’s not that, it’s like, it’s not illegal for a sitting president to say, no, I’m not gonna commit to a peaceful transfer of power, right, we’ll wait and see whether I win. If I win, it was, the election was valid. If I lose, it was fraudulent, right?
Lex Fridman (43:41):
But aren’t those humorous perturbations to our system of civility such that we know what the limits are, and now we start to think that and have these kinds of discussions?
Sam Harris (43:50):
That wasn’t a humorous perturbation because he did everything he could. Granted, he wasn’t very competent, but he did everything he could to try to steal the election. I mean, the irony is, he claimed to have an election stolen from him, all the while doing everything he could to steal it, declaring it fraudulent in advance, trying to get the votes to not be counted as the evening wore on, knowing that they were gonna be disproportionately Democrat votes because of the position he took on mail-in ballots. I mean, all of it was fairly calculated.
(44:28):
The whole circus of the clown car that crashed into Four Seasons Landscaping, right, and you got Rudy Giuliani with his hair dyed, and you got Sidney Powell and all these grossly incompetent people lying as freely as they could breathe about election fraud, right? And all of these things are getting thrown out by largely Republican election officials and Republican judges.
(44:56):
It wasn’t for want of trying that he didn’t maintain his power in this country. He really tried to steal the presidency. He just was not competent, and the people around him weren’t competent. So that’s a good thing, and it’s worth not letting that happen again.
Lex Fridman (45:11):
But he wasn’t competent, so he didn’t do everything he could.
Sam Harris (45:15):
Well, no, he did everything he could. He didn’t do everything that could have been done by someone more competent.
Lex Fridman (45:21):
Right, but the tools you have as a president, you could do a lot of things. You can declare emergencies, especially during COVID. You could postpone the election. You can create military conflict, that any kind of reason to postpone the election.
Sam Harris (45:35):
There’s a lot of stuff. But he tried to do things, and he would have to have done those things through other people, and there are people who refuse to do those things. There are people who said they would quit. They would quit publicly, right? I mean, you start, again, there are multiple books written about the last hours of this presidency, and the details are shocking in what he tried to do and tried to get others to do. And it’s awful, right? I mean, it’s just awful that we were that close to something, to a true unraveling of our political process. I mean, it’s the only time in our lifetime that anything like this has happened, and it’s deeply embarrassing, right, on the world stage. It’s just like we looked like a banana republic there for a while, and we’re the lone superpower.
(46:32):
It’s not good, right? And so we shouldn’t, there’s no, the people who thought, well, we just need to shake things up, and this is a great way to shake things up, and having people storm our Capitol and smear shit on the walls, that’s just more shaking things up, right? It’s all just for the lulz.
(46:53):
There’s a nihilism and cynicism to all of that, which, again, in certain people, it’s understandable. Frankly, it’s not understandable if you’ve got a billion dollars and you have a compound in Menlo Park or wherever, it’s like, there are people who are cheerleading this stuff who shouldn’t be cheerleading this stuff and who know that they can get on their Gulfstream and fly to their compound in New Zealand if everything goes to shit, right? So there’s a cynicism to all of that that I think we should be deeply critical of.
Lex Fridman (47:22):
What I’m trying to understand is not, and analyze, is not the behavior of this particular human being, but the effect it had, in part, on the division between people, and to me, the degree, the meme of Sam Harris’s brain being broken by Trump represents, you’re like the person I would look to to bridge the division.
Sam Harris (47:47):
Well, I don’t think there is something profitably to be said to someone who’s truly captivated by the personality cult of Trumpism, right? Like, there’s nothing that I’m gonna say to, there’s no conversation I’m gonna have with Candace Owens, say, about Trump that’s gonna converge on something reasonable, right? You don’t think so? No, I mean, I haven’t tried with Candace, but I’ve tried with many people who are in that particular orbit. I mean, I’ve had conversations with people who won’t admit that there’s anything wrong with Trump.
Lex Fridman (48:23):
Anything. So I’d like to push for the empathy versus reason, because when you operate in the space of reason, yes, but I think there’s a lot of power in you showing, in you, Sam Harris, showing that you’re willing to see the good qualities of Trump, publicly showing that. I think that’s the way to win over Candace Owens.
Sam Harris (48:43):
Well, but he has so few of them. He has fewer good qualities than virtually anyone I can name, right? So he’s funny, I’ll grant you that he’s funny. He’s a good entertainer.
Lex Fridman (48:55):
There’s others look at just policies and actual impacts he had.
Sam Harris (48:58):
I’ve admitted that. No, no, so I’ve admitted that many of his policies I agree with. Many, many of his policies. So probably more often than not, at least on balance, I agreed with his policy that we should take China seriously as an adversary. I think, I mean, again, you have to, there’s a lot of fine print to a lot of this, because the way he talks about these things and many of his motives that are obvious are things that I don’t support, but take immigration.
(49:33):
I think there’s, it’s obvious that we should have control of our borders, right? Like I don’t see the argument for not having control of our borders. We should let in who we want to let in, and we should keep out who we want to keep out, and we should have a sane immigration policy. So I didn’t necessarily think it was a priority to build the wall, but I didn’t, I never criticized the impulse to build the wall, because if tens of thousands, hundreds of thousands of people are coming across that border and we are not in a position to know who’s coming, that seems untenable to me. So, and I can recognize that many people in our society are on balance the victims of immigration, and there is in many cases a zero sum contest between the interests of actual citizens and the interests of immigrants, right? So I think we should have control of our borders. We should have a sane and compassionate immigration policy. We should have, we should let in refugees, right? So I didn’t, you know, Trump on refugees was terrible, but no, like, I would say 80% of the policy concerns people celebrated in him are concerns that I either share entirely or certainly sympathize with. Right, so like, that’s not, that’s not the issue. The issue is-
Lex Fridman (50:58):
The threat to democracy and so forth.
Sam Harris (50:59):
Well, the issue is largely what you said it was. It’s not so much the person, it’s the effect on everything he touches, right? He just, he has this superpower of deranging and destabilizing almost everything he touches and sullying and compromising the integrity of almost anyone who comes into his orbit. I mean, so you looked at these people who served as chief of staff or, you know, in various cabinet positions, people had real reputations, you know, for probity and level-headedness, you know, whether you share their politics or not. I mean, these were real people. These were not, you know, some of them were goofballs, but, you know, many people who just got totally trashed by proximity to him and then trashed by him when they finally parted company with him.
(51:58):
Yeah, I mean, it’s just people bent over backwards to accommodate his norm violations. And it was bad for them and it was bad for our system. And, but none of that discounts the fact that we have a system that really needs a proper house cleaning. Yes, there are bad incentives and entrenched interests.
(52:25):
And I’m not a fan of the concept of the deep state, but, because it, you know, it’s been so propagandized, but yes, there’s something like that, you know, that is not flexible enough to respond intelligently to the needs of the moment, right? So there’s a lot of rethinking of government and of institutions in general that I think we should do, but we need smart, well-informed, well-intentioned people to do that job. And the well-intentioned part is hugely important, right? Just give me someone who is not the most selfish person anyone has ever heard about in their lifetime, right?
(53:16):
And what we got with Trump was literally the one most selfish person I think anyone could name. I mean, and again, there’s so much known about this, man. That’s the thing. It’s like, it predates his presidency. We knew this guy 30 years ago. And this is why, to come back to those inflammatory comments about Hunter Biden’s laptop, the reason why I can say with confidence that I don’t care what was on his laptop is that there is, and that includes any evidence of corruption on the part of his father, right? Now, there’s been precious little of that that’s actually emerged. So it’s like, there is no, as far as I can tell, there’s not a big story associated with that laptop as much as people bang on about a few emails. But even if there were just obvious corruption, right? Like Joe Biden was at this meeting and he took this amount of money from this shady guy for bad reasons, right?
(54:15):
Given how visible the lives of these two men have been, right, I mean, given how much we know about Joe Biden and how much we know about Donald Trump and how they have lived in public for almost as long as I’ve been alive, both of them, the scale of corruption can’t possibly balance out between the two of them, right? If you show me that Joe Biden has this secret life where he’s driving a Bugatti and he’s living like Andrew Tate, right? And he’s doing all these things I didn’t know about, okay, then I’m gonna start getting a sense that, all right, maybe this guy is way more corrupt than I realized. Maybe there is some deal in Ukraine or with China that is just, like this guy is not who he seems, he’s not the public servant he’s been pretending to be, he’s been on the take for decades and decades, and he’s just, he’s as dirty as can be, he’s all mobbed up and it’s a nightmare, and he can’t be trusted, right? That’s possible if you show me that his life is not at all what it seems. But on the assumption that I, having looked at this guy for literally decades, right?
(55:21):
And knowing that every journalist has looked at him for decades, just how many affairs is he having, just how much, how many drugs is he doing, how many houses does he have, what are the obvious conflicts of interest? You hold that against what we know about Trump, right?
(55:41):
And I mean, the litany of indiscretions you can put on Trump’s side that testify to his personal corruption, to testify to the fact that he has no ethical compass, there’s simply no comparison, right? So that’s why I don’t care about what’s on the laptop. Now, if you tell me Trump is no longer running for president in 2024, and we can put Trumpism behind us, and now you’re saying, listen, there’s a lot of stuff on that laptop that makes Joe Biden look like a total asshole. Okay, I’m all ears, right?
(56:14):
I mean, it was a forced, in 2020, it was a forced choice between a sitting president who wouldn’t commit to a peaceful transfer of power and a guy who’s obviously too old to be president, who has a crack-addicted son who lost his laptop. And I just knew that I was gonna take Biden in spite of whatever litany of horrors was gonna come tumbling out of that laptop.
Lex Fridman (56:41):
And that might involve sort of, so the actual quote is, Hunter Biden literally could have had the corpses of children in the basement. There’s a dark humor to it, right? Which is, I think you speak to. I would not have cared. There’s nothing, it’s Hunter Biden, it’s not Joe Biden. Whatever the scope of Joe Biden’s corruption is, it is infinitesimally compared to the corruption we know Trump was involved in. It’s like a firefly to the sun is what you’re speaking to. But let me make the case that you’re really focused on the surface stuff, that it’s possible to have corruption that masquerades in the thing we mentioned, which is civility. You can spend hundreds of billions of dollars or trillions towards a war in the Middle East, for example, something that you’ve changed your mind on in terms of the negative impact it has on the world.
(57:32):
And that, the military-industrial complex, everybody’s very nice, everybody’s very civil, just very upfront, here’s how we’re spending the money. Yeah, sometimes somehow disappears in different places, but that’s the way war is complicated. And everyone is very polite. There’s no Coke and strippers or whatever is on the laptop. It’s very nice and polite. In the meanwhile, hundreds of thousands of civilians die. Hate, just an incredible amount of hate is created because people lose their family members, all that kind of stuff, but there’s no strippers and Coke on a laptop.
Sam Harris (58:07):
Yeah, but it’s not just superficial. It is, when someone only wants wealth and power and fame, that is their objective function, right? They’re like a robot that is calibrated just to those variables, right? And they don’t care about the risks we run on any other front. They don’t care about, I mean, environmental risk, pandemic risk, nuclear proliferation risk, none of it, right? They’re just tracking fame and money and whatever can personally redound to their self-interest along those lines. And they’re not informed about the other risks we’re running, really. I mean, in Trump, you had a president who was repeatedly asking his generals, why couldn’t we use our nuclear weapons? Why can’t we have more of them? Why do I have fewer nuclear weapons than JFK? Right, as though that were a sign of anything other than progress, right?
(59:13):
And this is the guy who’s got the button, right? I mean, somebody’s following him around with a bag waiting to take his order to launch, right? That is a, it’s just, it’s a risk we should never run. Risk we should never run. One thing Trump has going for him, I think, is that he doesn’t drink or do drugs, right? I don’t know, there’s, you know, people allege that he does speed, but, you know, let’s take him at his word. He’s not deranging himself with pharmaceuticals, at least, but apart from Diet Coke, but-
Lex Fridman (59:51):
There’s nothing wrong, just for the record, let me push back on that. There’s no-
Sam Harris (59:55):
There’s nothing wrong with Diet Coke, yeah, I’ll- You can see we have a very large amount. I occasionally have some myself.
Lex Fridman (59:59):
There’s no medical, there’s no scientific evidence that I observed the negatives of, you know, all those studies about aspartame and all of that, it’s, no, I don’t know.
Sam Harris (01:00:08):
I’d like, I hope you’re right. Yeah, I mean, everything you said about the military-industrial complex is true, right? And it’s been, we’ve been worrying about that on both sides of the aisle for a very long time. I mean, that’s just, that phrase came from Eisenhower. It’s, I mean, so much of what ails us is a story of bad incentives, right? And bad incentives are so powerful that they corrupt even good people, right?
(01:00:42):
How much more do they corrupt bad people, right? Like, so it’s like, you want to, at minimum, you want reasonably good people, at least non-pathological people in the system trying to navigate against the grain of bad incentives. And better still, all of us can get together and try to diagnose those incentives and change them, right? And we will really succeed when we have a system of incentives where the good incentives are so strong that even bad people are effortlessly behaving as though they’re good people because they’re so successfully incentivized to behave that way, right?
(01:01:25):
That’s, and so it’s almost the inversion of our current situation. So yes, and you say I changed my mind about the war. Not quite. I mean, I was never a supporter of the war in Iraq. I was always worried that it was a distraction from the war in Afghanistan. I was a supporter of the war in Afghanistan. And I will admit, in hindsight, that looks like, at best, a highly ambiguous and painful exercise, more likely a fool’s errand, right? It’s like that, it did not turn out well.
(01:02:01):
It wasn’t for want of trying. I don’t, you know, I have not done a deep dive on all of the failures there. And maybe all of these failures are failures in principle. I mean, maybe it’s just, maybe that’s not the kind of thing that can be done well by anybody, whatever our intentions. But yeah, the move to Iraq always seemed questionable to me. And when we knew the problem, the immediate problem at that moment, you know, al-Qaeda was in Afghanistan and then bouncing to Pakistan.
(01:02:37):
Anyway, you know, so yes, but my sense of the possibility of nation building, my sense of, you know, insofar as the neocon spirit of, you know, responsibility and idealism, that, you know, America was the kind of nation that should be functioning in this way as the world’s cop. And we’ve got, we have to get in there and untangle some of these knots by force rather often, because, you know, if we don’t do it over there, we’re gonna have to do it over here kind of thing. Yeah, some of that has definitely changed for me in my thinking.
(01:03:20):
And there are obviously cultural reasons why it failed in Afghanistan. And if you can’t change the culture, you’re not gonna force a change at gunpoint in the culture, or it certainly seems that that’s not gonna happen. And it took us over 20 years apparently to realize that.
Lex Fridman (01:03:40):
That’s one of the things you realize with a war is there’s not going to be a strong signal that things are not working. You can just keep pouring money into a thing, a military effort.
Sam Harris (01:03:49):
Well, also there are signs of it working too. You have all the stories of girls now going to school, right, you know, the girls are getting battery acid thrown in their faces by religious maniacs. And then we come in there and we stop that. And now girls are getting educated and there’s, and that’s all good. And our intentions are good there. And I mean, we’re on the right side of history there. The girls should be going to school. You know, Malala Yousafzai should have the Nobel prize and she shouldn’t have been shot in the face by the Taliban, right?
(01:04:21):
We know what the right answers are there. The question is, what do you do when there are enough, in this particular case, religious maniacs who are willing to die and let their children die in defense of crazy ideas and moral norms that belong in the seventh century? And it’s a problem we couldn’t solve. And we couldn’t solve it even though we spent, you know, trillions of dollars to solve it.
Lex Fridman (01:04:45):
This reminded me of the thing that you and Jack Dorsey jokingly had for a while, the discussion about banning Donald Trump from Twitter. But does any of it bother you now that Twitter files came out that, I mean, this has to do with sort of the Hunter laptop, Hunter Biden laptop story. Does it bother you that there could be a collection of people that make decisions about who to ban and not? And that could be susceptible to bias and to ideological influence?
Sam Harris (01:05:21):
Well, I think it always will be, or in the absence of perfect AI, it always will be.
Lex Fridman (01:05:29):
And this becomes relevant with AI as well. Because there’s some censorship on AI happening. And it’s an interesting question there as well.
Sam Harris (01:05:35):
I don’t think Twitter is as important as people think it is, right? And I used to think it was more important when I was on it, and now that I’m off of it, I think it’s, I mean, first let me say it’s just an unambiguously good thing, in my experience, to delete your Twitter account, right? It’s like, it is just, even the good parts of Twitter that I miss were bad in the aggregate, in the degree to which it was fragmenting my attention, the degree to which my life was getting doled out to me in periods between those moments where I checked Twitter, right, and had my attention divert. And I was not a crazy Twitter addict. I mean, I was probably a pretty normal user. I mean, I was not someone who was tweeting multiple times a day, or even every day, right? I mean, I probably, I think I probably averaged something like one tweet a day, I think I averaged. But in reality, it was like, there’d be like four tweets one day, and then I wouldn’t tweet for the better part of a week.
(01:06:40):
And, but I was looking a lot because it was my newsfeed. I was just following, you know, 200 very smart people, and I would just wanted to see what they were paying attention to, and they would recommend articles, and I would read those articles. And then when I would read an article, then I would thought I should signal boost, I would tweet. And so all of that seemed good. And like, that’s all separable from all of the odious bullshit that came back at me in response to this, largely in response to this Hunter Biden thing.
(01:07:10):
But even the good stuff has a downside. And it comes at just this point of, your phone is this perpetual stimulus of, which is intrinsically fragmenting of time and attention. And now my phone is much less of a presence in my life. And it’s not that I don’t check Slack or check email. And I, you know, I use it to work, but my sense of just what the world is, and my sense of my place in the world, the sense of where I exist as a person has changed a lot by deleting my Twitter account. I mean, I had a, and it’s just, it’s, and the things that I think, I mean, we all know this phenomenon. I mean, we say of someone, that person’s too online, right? Like, what does it mean to be too online? And where do you draw that boundary? How do you know what constitutes being too online?
(01:08:12):
Well, in some sense, just being, I think being on social media at all is to be too online. I mean, given what it does to, given the kinds of information it signal boosts, and given the impulse it kindles in each of us to reach out to our audience in specific moments and in specific ways, right? It’s like, there are lots of moments now where I have an opinion about something, but there’s nothing for me to do with that opinion, right? Like, there’s no Twitter, right? So like, there are lots of things that I would have tweeted in the last months that are not the kind of thing I’m gonna do a podcast about. I’m not gonna roll out 10 minutes on that topic on my podcast. I’m not gonna take the time to really think about it. But had I been on Twitter, I would have reacted to this thing in the news or this thing that somebody did, right? What do you do with that thought now?
Lex Fridman (01:09:10):
I just let go of it. Like, chocolate ice cream is the most delicious thing.
Sam Harris (01:09:14):
Yeah, it’s usually not that sort of thing, but it’s just… But then you look at the kinds of problems people create for themselves. You look at the life-deranging and reputation-destroying things that people do, and I look at the analogous things that have happened to me, I mean, the things that have really bent my life around professionally over the past decade. So much of it is Twitter. I mean, honestly, in my case, almost 100% of it was Twitter. The controversies I would get into, the things I would think I would have to respond to, like I would release a podcast on a certain topic, I would see some blowback on Twitter.
(01:09:56):
It would give me the sense that there was some signal that I really had to respond to. Now that I’m off Twitter, I recognize that most of that was just… It was totally specious, right? It was not something I had to respond to. But yet I would then do a cycle of podcasts responding to that thing, that like taking my foot out of my mouth or taking someone else’s foot out of my mouth, and it became this self-perpetuating cycle which…
(01:10:27):
I mean, if you’re having fun, great. I mean, if it’s generative of useful information and engagement professionally and psychologically, great. And there was some of that on Twitter. I mean, there were people who I’ve connected with because one of us DMed the other on Twitter, and it was hard to see how that was gonna happen otherwise. But it was largely just a machine for manufacturing unnecessary controversy.
Lex Fridman (01:11:03):
Do you think it’s possible to avoid the drug of that? So now that you’ve achieved the Zen state, is it possible for somebody like you to use it in a way that doesn’t pull you into the whirlpool? And so anytime there’s attacks, you just… I mean, that’s how I tried to use it.
Sam Harris (01:11:18):
Yeah, but it’s not the way I wanted to use it. It’s not the way it promises itself as a… You wanted to have debate. I wanted to actually communicate with people. I wanted to hear from the person because, again, it’s like being in Afghanistan, right? It’s like there are the potted cases where it’s obviously good, right? It’s like in Afghanistan, the girl who’s getting an education, that is just here. That’s why we’re here. That’s obviously good.
(01:11:46):
I have those moments on Twitter where it’s okay, I’m hearing from a smart person who’s detected an error, I made in my podcast or in a book, or they’ve just got some great idea about something that I should spend time on, and I would never have heard from this person in any other format, and now I’m actually in dialogue with them, and it’s fantastic.
(01:12:06):
That’s the promise of it, to actually talk to people. And so I kept getting lured back into that. No, the sane or sanity-preserving way of using it is just as a marketing channel. You just put your stuff out there, and you don’t look at what’s coming back at you. And I’m on other social media platforms that I don’t even touch. I mean, my team posts stuff on Facebook and on Instagram. I never even see what’s on there.
Lex Fridman (01:12:35):
So you don’t think it’s possible to see something and not let it affect your mind?
Sam Harris (01:12:39):
No, that’s definitely possible, but the question is, and I did that for vast stretches of time, but then the promise of the platform is dialogue and feedback. So why am I, if I know, for whatever reason, I’m gonna see 99 to one awful feedback, bad faith feedback, malicious feedback, some of it’s probably even bots, and I’m not even aware of who’s a person, who’s a bot, but I’m just gonna stare into this funhouse mirror of acrimony and dishonesty that is going to, I mean, the reason why I got off is not because I couldn’t recalibrate and find equanimity again with all the nastiness that was coming back at me, and not that I couldn’t ignore it for vast stretches of time, but I could see that I kept coming back to it hoping that it would be something that I could use, a real tool for communication, and I was noticing that it was insidiously changing the way I felt about people, both people I know and people I don’t know, right? Like people, mutual friends of ours who are behaving in certain ways on Twitter, which just seemed insane to me, and then that became a signal I felt like I had to take into account somehow, right? You’re seeing people at their worst, you have both friends and strangers, and I felt that it was, as much as I could sort of try to recalibrate for it, I felt that I was losing touch with what was real information, because people are performing, people are faking, people are not themselves, or you’re just seeing people at their worst, and so I felt like, all right, what was being advertised to me here on a, not just a daily basis, a hourly basis, or an increment sometimes of multiple times an hour, I mean, I probably check Twitter at minimum 10 times a day, and maybe I was checking it 100 times a day on some days, right, where things were really active and I was really engaged with something.
(01:14:55):
What was being delivered into my brain there was subtly false information about how dishonest and, you know, just generally unethical, totally normal people are capable of being, right? It was like, it is a funhouse mirror. I was seeing the most grotesque versions of people who I know, right? People who I know I could sit down at dinner with and they would never behave this way, and yet they were coming at me on Twitter.
(01:15:32):
You know, I mean, it was essentially turning ordinary people into sociopaths, right? It’s like, people are just, you know, and there are analogies that many of us have made. It’s like, one analogy is road rage, right? Like, people behave in the confines of a car in ways that they never would if they didn’t have this metal box around them, you know, moving at speed. And it’s, you know, all of that becomes quite hilarious and, you know, obviously dysfunctional when they actually have to stop at the light next to the person they just flipped off and they realize they didn’t realize, they didn’t understand that the person coming out of that car next to them with cauliflower ear is someone who they never would have, you know, rolled their eyes at in public because they would have taken one look at this person and realized this is the last person you want to fight with.
Lex Fridman (01:16:19):
That’s one of the heartbreaking things, is to see people who I know, who I admire, who I know are friends, be everything from snarky to downright mean, derisive towards each other. It doesn’t make any sense. Like, this is the only place where I’ve seen people I really admire who have had a calm head about most things, like really be shitty to other people. It’s probably the only place I’ve seen that. And I don’t, I tend, I choose to maybe believe that that’s not really them. There’s something about the system. Like, if you go paintballing,
Sam Harris (01:16:59):
if you, Jordan Peterson, and whoever, go paintball. You’re gonna shoot your friends, yeah.
Lex Fridman (01:17:02):
Yeah, you’re gonna shoot your friends, but you kind of accept that that’s kind of what you’re doing in this little game that you’re playing. But it’s sometimes hard to remind yourself of that.
Sam Harris (01:17:10):
Well, and I think I was guilty of that, definitely. You know, I don’t think, there’s nothing, I don’t think I ever did anything that I really feel bad about. But yeah, it was always pushing me to the edge of snideness somehow. And it’s just not healthy. It’s not, so the reason why I deleted my Twitter account in the end was that it was obviously making me a worse person. And so, and yeah, is there some way to be on there where it’s not making you a worse person? I’m sure there is, but it’s, given the nature of the platform, and given what was coming back at me on it, the way to do that is just to basically use it as a one-way channel of communication. It’s just marketing. You know, it’s like, here’s what I’m paying attention to. Look at it if you want to, and you just push it out, and then you don’t look at what’s coming back at you.
Lex Fridman (01:18:09):
I put out a call for questions on Twitter, and actually, quite surprisingly, there’s a lot of good. I mean, they’re like, even if they’re critical, they’re like being thoughtful, which is nice.
Sam Harris (01:18:21):
I used it that way, too, and that was what kept me hooked.
Lex Fridman (01:18:24):
But then there’s also TouchBalls69 wrote a question.
Sam Harris (01:18:29):
Ask what? I can’t imagine. This is part of it, but one way to solve this is, you know, we’ve got to get rid of anonymity for this.
Lex Fridman (01:18:37):
Let me ask the question. Ask Sam why he sucks was the question.
Sam Harris (01:18:40):
Yeah, that’s good. Well, one reason why I sucked was Twitter. That was, and I’ve since solved that problem. So TouchBalls69 should be happy that I suck a little bit less now that I’m off Twitter. I mean, I don’t have to hear from TouchBalls69 on the regular.
Lex Fridman (01:18:59):
The fact that you have to see that, it probably can have a negative effect, just even in moderation, just to see that there is, like for me, the negative effect is slightly losing faith in the underlying kindness of humanity. Yeah, that was for me, yeah. You can also just reason your way out of it, saying that this is anonymity and this is kind of fun and it’s kind of just the shit show of Twitter. It’s okay, but it does mentally affect you a little bit.
Sam Harris (01:19:28):
Like I don’t read too much into that kind of comment. It’s like, that’s just trolling. And it’s, I get what’s, I understand the fun the person is having on the other side of that. It’s like- Do you though? I do, well, I do. I don’t, I mean, I don’t behave that way, but I do, and for all I know, that person could be 16 years old, right? So it’s like-
Lex Fridman (01:19:53):
It could be also an alt-account for Elon, I don’t know.
Sam Harris (01:19:56):
Well, yeah, that’s right, yeah, yeah, yeah. No, I’m pretty sure Elon would just tweet that under his own name at this point.
Lex Fridman (01:20:04):
Oh, man, you love each other. Okay, so the, do you think, so speaking of which, now that Elon has taken over Twitter, is there something that he could do to make this platform better? This Twitter and just social media in general, but because of the aggressive nature of his innovation that he’s pushing, is there any way to make Twitter a pleasant place for Sam Harris?
Sam Harris (01:20:30):
Maybe. Like in the next five years? I don’t know, I think I’m agnostic as to whether or not he or anyone could make a social media platform that really was healthy.
Lex Fridman (01:20:40):
So you were just observing yourself, week by week, seeing the effect it has on your mind and on how much you’re actually learning and growing as a person, and it was negative.
Sam Harris (01:20:48):
Yeah, and I’d also seen the negativity in other people’s lives. I mean, it’s obviously, I mean, he’s not gonna admit it, but I think it’s obviously negative for Elon, right? I mean, it’s just not, it’s- That was one of the things that, you know, when I was looking into the Funhaus mirror, I was also seeing the Funhaus mirror on his side of Twitter, and it was just even more exaggerated. It’s like, whoa. When I was asking myself, why is he spending his time this way? I then reflected on why was I spending my time this way, to a lesser degree, right? And at lesser scale and at lesser risk, frankly, right?
(01:21:28):
And so, and it was just so, it’s not just Twitter. I mean, this isn’t part, an internet phenomenon. It’s like the whole Hunter Biden mess that you- Explored. Explored. That was based on, I mean, it was on somebody’s podcast, but that was based on a clip taken from that podcast, which was highly misleading as to the general shape of my remarks on that podcast, even, you know, I had to then do my own podcast untangling all of that and admitting that even in the full context, I was not speaking especially well and didn’t say exactly what I thought in a way that would have been recognizable to anyone, you know, even someone with not functioning by a spirit of charity, but the clip was quite distinct from the podcast itself. The reality is, is that we’re living in an environment now where people are so lazy and their attention is so fragmented that they only have time for clips. 99% of people will see a clip and will assume there’s no relevant context I need to understand what happened in that clip, right? And obviously the people who make those clips know that, right, and they’re doing it quite maliciously. And in this case, the person who made that clip and subsequent clips of other podcasts was quite maliciously trying to engineer, you know, some reputational immolation for me and being signal boosted by Elon and other prominent people who can’t take the time to watch anything other than a clip, even when it’s their friend or someone who’s ostensibly their friend in that clip, right? So it’s a total failure, an understandable failure of ethics that everyone is so short on time and they’re so fucking lazy that, and we now have these contexts in which we react so quickly to things, right? Like Twitter is inviting an instantaneous reaction to this clip that it’s just too tempting to just say something and not know what you’re even commenting on. And most of the people who saw that clip don’t understand what I actually think about any of these issues. And the irony is people are gonna find clips from this conversation that are just as misleading and they’re gonna export those and then people are gonna be dunking on those clips. And, you know, we’re all living and dying by clips now. And it’s dysfunctional.
Lex Fridman (01:24:08):
See, I think it’s possible to create a platform. I think we will keep living on clips. But, you know, when I saw that clip of you talking about children and so on, just knowing that you have a sense of humor, you just went to a dark place in terms of humor. So like, I didn’t even bother. And then I knew that the way clips work is that people will use it for virality’s sake. But the giving a person benefit of the doubt, that’s not even the right term. It’s not like I was, it’s really like interpreting it
Sam Harris (01:24:42):
in the context of knowing your past. The truth is you even need, like I even give Trump the benefit of the doubt when I see a clip of Trump. Because there are famous clips of Trump that are very misleading as to what he was saying in context and I’ve been honest about that. Like the whole, you know, there were good people on both sides scandal around his remarks after Charlottesville. Like the clip that got exported and got promoted by everyone, you know, left of center, from Biden on down, you know, the New York Times, CNN, there’s nobody that I’m aware of who has honestly, you know, apologized for what they did with that clip. That clip, he did not say what he seemed to be saying in that clip about the Nazis at Charlottesville, right? And I have always been very clear about that. So it’s just, you know, even people who I think should be marginalized and people who should be defenestrated because they really are terrible people who are doing dangerous things and for bad reasons, I think we should be honest about what they actually meant in context, right? And this goes to anyone else we might talk about, you know, who’s more, where the case is much more confusing, but yeah.
(01:26:08):
So everyone’s, it’s just so, and then I’m sure we’re gonna get to AI, but you know, the prospect of being able to manufacture clips with AI and deep fakes and that where it’s gonna be hard for most people most of the time to even figure out that whether they’re in the presence of something real, you know, forget about being divorced from context. There was no context. I mean, that is, that’s a misinformation apocalypse that is, we are right on the cusp of, and you know, it’s terrifying.
Lex Fridman (01:26:42):
So, fine. Or it could be just a new world, like we’re Alice going to Wonderland where humor is the only thing we have and it will save us. Maybe in the end, Trump’s approach to social media was the right one after all. Nothing is true and everything’s absurd.
Sam Harris (01:26:57):
Yeah, but we can’t live that way. People function on the basis of what they assume is true, right? They think, you know. People have functioned. Well, to do anything. It’s like, I mean, you have to know what you think is going to happen, or you have to at least give a probabilistic weighting over the future.
(01:27:15):
Otherwise, you’re going to be incapacitated by, you’re not going to, like, people want certain things and they have to have a rational plan to get those desires gratified. And they don’t want to die. They don’t want their kids to die. You tell them that there’s a comet hurtling toward Earth and they should get outside and look up, right? They’re going to do it. And if it turns out it’s misinformation, you know, it’s going to matter because it comes down to, like, what medicines do you give your children, right? Like, we’re going to be manufacturing fake journal articles. I mean, this is, I’m sure someone’s using ChatGPT for this, you know, as we speak.
(01:27:56):
And if it’s not credible, if it’s not persuasive now to most people, I mean, honestly, I don’t think we’re going to, I’ll be amazed if it’s a year before we can actually create journal articles that would take, you know, a PhD to debunk that are completely fake. And there are people who are celebrating this kind of, you know, coming cataclysm. But it’s just, there are the people who don’t have anything to lose who are celebrating it or just are so confused that they just don’t even know what’s at stake. And then there are the people who have met, the few people who we could count on a few hands who have managed to insulate themselves, or at least imagine they’ve insulated themselves from the downside here enough that they’re not implicated in the great unraveling we are witnessing or could witness.
Lex Fridman (01:28:52):
So the shaking up of what is true. So actually that returns us to experts. Do you think experts can save us? Is there such thing as expertise and experts in something? How do you know if you’ve achieved it?
Sam Harris (01:29:03):
I think it’s important to acknowledge up front that there’s something paradoxical about how we relate to authority, especially within science. And I don’t think that paradox is going away, and it’s just, it doesn’t have to be confusing. It’s just, and it’s not truly a paradox. It’s just like there are different moments in time. So it is true to say that within science or within rationality generally, I mean, whenever you’re having a fact-based discussion about anything, it is true to say that the truth or falsity of a statement does not even slightly depend on the credentials of the person making the statement. So it doesn’t matter if you’re a Nobel laureate. You can be wrong. The thing you could, the last sentence you spoke could be total bullshit.
(01:30:00):
And it’s also possible for someone who’s deeply uninformed to be right about something or to be right for the wrong reasons, or someone just gets lucky or someone, or, and there are middling cases where you have like a backyard astronomer who’s got no credentials, but he just loves astronomy, and he’s got a telescope, and he’s spent a lot of time looking at the night sky, and he discovers a comet that no one else has seen, not even the professional expert astronomers. I mean, I gotta think that happens less and less now, but some version of that keeps happening, and it may always keep happening in every area of expertise, right?
(01:30:44):
So it’s true that truth is orthogonal to the reputational concerns we have among apes who are talking about the truth, but it is also true that most of the time, real experts are much more reliable than frauds or people who are not experts, right? So, and expertise really is a thing, right? And when you’re flying an airplane in a storm, you don’t want just randos come into the cockpit saying, listen, I’ve got a new idea about how to, how we should tweak these controls, right? You want someone who’s a trained pilot, and that training gave them something, right? It gave them a set of competences and intuitions, and they know what all those dials and switches do, right? And I don’t, right? I shouldn’t be flying that plane.
(01:31:40):
So when things really matter, and putting this at 30,000 feet in a storm sharpens this up, we want real experts to be in charge, right? And we are at 30,000 feet a lot of the time on a lot of issues, right? And whether they’re public health issues, whether it’s a geopolitical emergency like Ukraine, climate change, I mean, just pick your topic.
(01:32:08):
There are real problems, and the clock is rather often ticking, and their solutions are non-obvious, right? And so expertise is a thing, and deferring to experts much of the time makes a lot of sense. At minimum, it prevents spectacular errors of incompetence and just foolhardiness.
(01:32:42):
But even in the case of some, where you’re talking about someone, I mean, people like ourselves, who are like, we’re well-educated, we’re not the worst possible candidates for the Dunning-Kruger effect. When we’re going into a new area where we’re not experts, we’re fairly alert to the possibility that it’s not as simple as things seem at first, and we don’t know how our tools translate to this new area.
(01:33:05):
We can be fairly circumspect. But we’re also, because we’re well-educated, and we’re pretty quick studies, we can learn a lot of things pretty fast, and we can begin to play a language game that sounds fairly expert, right? And in that case, the invitation to do your own research, right, is when times are good, I view as an invitation to waste your time pointlessly, right, when times are good. Now, the truth is, times are not all that good, right? And we have the ongoing public display of failures of expertise. We have experts who are obviously corrupted by bad incentives. We’ve got experts who perversely won’t admit they were wrong when they, in fact, are demonstrated to be wrong. We’ve got institutions that have been captured by political ideology that’s not truth-tracking, and this whole woke encroachment into really every place, whether it’s universities, or science journals, or government, or, I mean, it’s just, like, that has been genuinely deranging.
(01:34:23):
So there’s a lot going on where experts, and the very concept of expertise has seemed to discredit itself. But the reality is is that there is a massive difference. When anything matters, when there’s anything to know about anything, there is a massive difference, most of the time, between someone who has really done the work to understand that domain and someone who hasn’t. And if I get sick or someone close to me gets sick, you know, I have a PhD in neuroscience, right? So I can read a medical journal article and understand a lot of it, right? And I, you know, so I’m just fairly conversant with medical terminology. And I understand its methods, and I’m alert to the difference, because I’ve, you know, because in neuroscience, I’ve spent hours and hours in journal clubs, you know, diagnosing, you know, and analyzing the difference between good and bad studies.
(01:35:18):
I’m alert to the difference between good and bad studies in medical journals, right? And I understand that bad studies can get published, and, you know, et cetera. And experiments can be poorly designed. I’m alert to all of those things. But when I get sick or when someone close to me gets sick, I don’t pretend to be a doctor, right? I’ve got no clinical experience. I don’t go down the rabbit hole on Google for days at a stretch trying to become a doctor, much less a specialist in the domain of problem that has been visited upon me or my family, right? So if someone close to me gets cancer, I don’t pretend to be an oncologist. I don’t go out and start, I don’t start reading, you know, in journals of oncology and try to really get up to speed as an oncologist, because it’s not, it’s, one, it’s a bad and potential, and very likely misleading use of my time, right? And it’s, if I decide, if I had, if I had a lot of runway, if I decided, okay, it’s really important for me to know everything I can. At this point, I wanna, I know someone’s gonna get cancer. I may not go back to school and become an oncologist, but what I wanna do is I wanna know everything I can know about cancer, right? So I’m gonna take the next four years and spend most of my time on cancer. Okay, I could do that, right? I still think that’s a waste of my time.
(01:36:46):
I still think at the end of, even at the end of those four years, I’m not gonna be the best person to form intuitions about what to do in the face of the next cancer that I have to confront. I’m still gonna want a better oncologist than I’ve become to tell me what he or she would do if they were in my shoes or in the shoes of my family member. I’m not advocating a blind trust in authority.
(01:37:14):
Like, if you get cancer and you’re talking to one oncologist and they’re recommending some course of treatment, by all means get a second opinion, get a third opinion, right, but it matters that those opinions are coming from real experts and not from, you know, Robert Kennedy Jr., you know, who’s telling you that, you know, you got it because you got a vaccine, right, it’s like, it’s just, we’re swimming in a sea of misinformation where you’ve got people who are moving the opinions of millions of others who should not have an opinion on these topics. Like, there’s no, there is no scenario in which you should be getting your opinion about vaccine safety or climate change or the war in Ukraine or anything else that we might wanna talk about from Candace Owens, right? It’s just like, she’s not a relevant expert on any of those topics.
(01:38:16):
And what’s more, she doesn’t seem to care, right? And she’s living in a culture that has amplified that not caring into a business model, an effective business model, right? So it’s just, it’s, and there’s something very Trumpian about all that. Like, that’s the problem, the problem is the culture, it’s not these specific individuals. So the paradox here is that expertise is a real thing and we defer to it a lot as a labor-saving device and just based on the reality that it’s very hard to be a polymath, right? And specialization is a thing, right? And so there are people who specialize in a very narrow topic, they know more about that topic than the next guy, no matter how smart that guy or gal is and that those differences matter. But it’s also true that when you’re talking about facts, sometimes the best experts are wrong, the scientific consensus is wrong. You get a sea change in the thinking of a whole field because one person who’s an outlier for whatever reason decides, okay, I’m gonna prove this point and they prove it, right? So somebody like the doctor who believed that stomach ulcers were not due to stress but were due to H. pylori infections, right? So he just drank a vial of H. pylori bacteria and proved and quickly got an ulcer and convinced the field that at minimum H. pylori was involved in that process.
(01:39:58):
Okay, so yes, everyone was wrong. That doesn’t disprove the reality of expertise. It doesn’t disprove the utility of relying on experts most of the time, especially in an emergency, especially when the clock is ticking, especially when you’re in this particular cockpit and you only have one chance to land this plane, right? You want the real pilot at the controls. But there’s just a few things to say.
Lex Fridman (01:40:28):
So one, you mentioned this example with cancer and doing your own research. There are several things that are different about our particular time in history. One, doing your own research has become more and more effective because you can read, the internet made information a lot more accessible so you can read a lot of different meta-analyses. You can read blog posts that describe to you exactly the flaws in the different papers that make up the meta-analyses. And you can read a lot of those blog posts that are conflicting with each other and you can take that information in and in a short amount of time, you can start to make good faith interpretations. For example, I don’t know, I don’t wanna overstate things, but if you suffer from depression, for example, then you could go to an expert and a doctor that prescribes you some medication. But you could also challenge some of those ideas and seeing what are the different medications, what are the different side effects, what are the different solutions to depression, all that kind of stuff. And I think depression is just a really difficult problem that’s very, I don’t wanna, again, state incorrect things, but I think it’s, there’s a lot of variability of what depression really means. So being introspective about the type of depression you have and the different possible solutions you have, just doing your own research as a first step before approaching a doctor or as you have multiple opinions could be very beneficial in that case. Now, that’s depression, that’s something that’s been studied for a very long time. With a new pandemic that’s affecting everybody, it’s, with the airplane, I would equate it to like 9-11 or something.
(01:42:14):
Did a new emergency just happen? And everybody, every expert in the world is publishing on it and talking about it. So doing your own research there could be exceptionally effective in asking questions. And then there’s a difference between experts, virologists, and it’s actually a good question, who is exactly the expert in a pandemic? But there’s the actual experts doing the research and publishing stuff, and then there’s the communicators of that expertise. And the question is, if the communicators are flawed to a degree where doing your own research is actually the more effective way to figure out policies and solutions, because you’re not competing with experts, you’re competing with the communicators of expertise. That could be WHO, CDC in the case of the pandemic, or politicians, or political type of science figures like Anthony Fauci. There’s a question there of the effectiveness of doing your research, your own research in that context. And the competing forces there, incentives that you’ve mentioned, is you can become quite popular by being contrarian, by saying everybody’s lying to you, all the authorities are lying to you, all the institutions are lying to you. So those are the waters you’re swimming in. But I think doing your own research in that kind of context could be quite effective.
Sam Harris (01:43:44):
Well, let me be clear. I’m not saying you shouldn’t do any research, right? I’m not saying that you shouldn’t be informed about an issue. I’m not saying you shouldn’t read articles on whatever the topic is. And yes, if I got cancer or someone close to me got cancer, I probably would read more about cancer than I’ve read thus far about cancer. And I’ve read some. So I’m not making a virtue of ignorance and a blind obedience to authority. And again, I recognize that authorities can discredit themselves or they can be wrong. They can be wrong even when there’s no discredit. There’s a lot we don’t understand about the nature of the world.
(01:44:26):
But still this vast gulf between truly informed opinion and bullshit exists. It always exists. And conspiracy thinking is rather often, most of the time, a species of bullshit, but it’s not always wrong, right? There are real conspiracies and there really are just awful corruptions born of bad incentives within our scientific processes, within institutions. And again, we’ve mentioned a lot of these things in passing, but what woke political ideology did to scientific communication during the pandemic was awful and it was really corrosive of public trust, especially on the right for understandable reasons. I mean, it was just, it was crazy. Some of the things that were being said and still is.
(01:45:27):
And these cases are all different. So you take depression. We just don’t know enough about depression for anyone to be that confident about anything, right? And there are many different modalities in which to interact with it as a problem, right? So there’s, yes, pharmaceuticals have whatever promise they have, but there’s certainly reason to be concerned that they don’t work well for everybody. And I mean, it’s obvious they don’t work well for everybody, but they do work for some people.
(01:45:60):
But again, depression is a multifactorial problem and there are different levels at which to influence it. And there are things like meditation, there are things like just life changes. And one of the perverse things about depression is that when you’re depressed, all of the things that would be good for you to do are precisely the things you don’t want to do. You don’t have any energy to socialize, you don’t want to get things done, you don’t want to exercise.
(01:46:27):
And all of those things, if you got those up and running, they do make you feel better in the aggregate. But the reality is that there are clinical level depressions that are so bad that it’s just, we just don’t have good tools for them. And it’s not enough to tell, there’s no life change. Someone’s gonna embrace that it’s going to be an obvious remedy for that. I mean, pandemics are obviously a complicated problem, but I would consider it much simpler than depression in terms of what’s on the menu to be chosen among the various choices. It’s less multifactorial. The logic by which you would make those choices, yeah. So it’s like, we have a virus, we have a new virus. It’s some version of bad. It’s human transmissible.
(01:47:19):
We’re still catching up. We’re catching up to every aspect of it. We don’t know how it spreads. We don’t know how- How effective masks are. Well, at a certain point, we knew it was respiratory, but we knew- But how respiratory, what that means. Yeah, and whether it’s spread by fomites. We were confused about a lot of things, and we’re still confused. It’s been a moving target this whole time, and it’s been changing this whole time, and our responses to it have been, we ramped up the vaccines as quickly as we could, but too quick for some, not quick enough for others. We could have done human challenge trials and got them out more quickly with better data, and I think that’s something we should probably look at in the future because to my eye, that would make ethical sense to do challenge trials, but…
(01:48:07):
And so much of my concern about COVID, I mean, many people are confused about my concern about COVID. My concern about COVID has, for much of the time, not been narrowly focused on COVID itself and how dangerous I perceive COVID to be as a illness. It has been, for the longest time, even more a concern about our ability to respond to a truly scary pathogen next time. Outside those initial months, give me the first six months to be quite worried about COVID and the unraveling of society, but… And the supply of toilet paper. You want to secure a steady supply of toilet paper, but beyond that initial period, when we had a sense of what we were dealing with and we had every hope that the vaccines are actually gonna work and we knew we were getting those vaccines in short order, right? Beyond that, and we knew just how dangerous the illness was and how dangerous it wasn’t.
(01:49:11):
For years now, I’ve just been worrying about this as a failed dress rehearsal for something much worse, right? I think what we prove to ourselves at this moment in history is that we have built informational tools that we do not know how to use, and we have made ourselves, we’ve basically enrolled all of human society into a psychological experiment that is deranging us and making it virtually impossible to solve coordination problems that we absolutely have to solve next time when things are worse.
Lex Fridman (01:49:47):
Do you understand who’s at fault for the way this unraveled? The way we didn’t seem to have the distrust in institutions and the institution of science that grew like seemingly exponentially or got revealed through this process, who is at fault here? And what’s to fix?
Sam Harris (01:50:09):
So much blame to go around, but so much of it is not a matter of bad people conspiring to do bad things. It’s a matter of incompetence and misaligned incentives and just ordinary, plain vanilla dysfunction.
Lex Fridman (01:50:28):
But my problem was that people like you, people like Brett Weinstein, people that I look to for reasonable, difficult conversations on difficult topics, have a little bit lost their mind, became emotional and dogmatic in style of conversation, perhaps not in the depth of actual ideas, but they’re, you know, a tweet’s something of that nature, not about you, but just it feels like the pandemic made people really more emotional than before. And then Kimball Musk responded, I think something I think you probably would agree with. Maybe not. I think it was the combo of Trump and the pandemic. Trump triggered the far left to be way more active than they could have been without him. And then the pandemic handed big government, nanny state, lefties, a huge platform on a silver platter, a one-two punch, and here we are.
Sam Harris (01:51:19):
Well, I would agree with some of that. I’m not sure how much to read into the nanny state concept,
Lex Fridman (01:51:25):
but yeah, like basically got people on the far left really activated. Yeah. And then gave control to, I don’t know if you say nanny state, but just control to government that when executed poorly has created a complete distrust in government.
Sam Harris (01:51:43):
My fear is that there was going to be that complete distrust anyway, given the nature of the information space, given the level of conspiracy thinking, given the gaming of these tools by an anti-vax cult. I mean, there really is an anti-vax cult that just ramped up its energy during this moment. But it’s a small one. It’s not to say that everything, every concern about vaccines is a species of, it was born of misinformation or born of this cult, but there is a cult that is just…
(01:52:19):
And the core of Trumpism is a cult. I mean, QAnon is a cult. And so there’s a lot of lying and there’s a lot of confusion. It’s almost impossible to exaggerate how confused some people are and how fully their lives are organized around that confusion. I mean, there are people who think that the world’s being run by pedophile cannibals and that Tom Hanks and Oprah Winfrey and Michelle Obama are among those cannibals.
(01:52:50):
I mean, adjacent to the pure crazy, there’s the semi-crazy, and adjacent to the semi-crazy, there’s the grifting, opportunist asshole. And the layers of bad faith are hard to fully diagnose. But the problem is all of this is getting signal-boosted by an outrage machine that is preferentially spreading misinformation. It has a business model that is guaranteed that it is preferentially sharing misinformation.
Lex Fridman (01:53:24):
Actually, just on a small tangent, how do you defend yourself against the claim that you’re a pedophile cannibal? It’s difficult. Here’s the case I would make, because I don’t think you can use reason. I think you have to use empathy. You have to understand.
Sam Harris (01:53:39):
Part of it, I mean, I find it very difficult to believe that anyone believes these things. I mean, I think that there’s, and I’m sure there’s some number of people who are just pretending to believe these things because it’s just, again, this is sort of like the 4chanification of everything. It’s just Pepe the Frog, right? None of this is what it seems. They’re not signaling an alliance with white supremacy or neo-Nazism, but they’re not not doing it. Like, they just don’t fucking care. It’s just cynicism overflowing its banks.
(01:54:13):
Right, it’s just fun to wind up the normies, right? Like, look at all the normies who don’t understand that a green frog is just a green frog, even when it isn’t just a green frog, right? It’s like they’re just, it’s just gumming up everyone’s cognitive bandwidth with bullshit, right? I get that that’s fun if you’re a teenager and you just want to vandalize our newsphere, but at a certain point, we have to recognize that real questions of human welfare are in play, right? There’s like, they’re really, there are wars getting fought or not fought, and there’s a pandemic raging, and there’s medicine to take or not take. But I mean, to come back to this issue of COVID, I don’t think my, I don’t think I got so out of balance around COVID. I think people are quite confused about what I was concerned about. I mean, like, there was a, yes, there was a period where I was crazy because anyone who was taking it seriously was crazy because they had no idea what was going on. And so it’s like, yes, I was wiping down packages with alcohol wipes, right?
(01:55:15):
Because people thought it was transmissible by touch, right? So, and then when we realized that was no longer the case, I stopped doing that. But, so there, again, it was a moving target. And a lot of things we did in hindsight around masking and school closures looked fairly dysfunctional, right? Unnecessary.
Lex Fridman (01:55:40):
I think the criticism that people would, that people would say about your talking about COVID, and maybe you can correct me, but you were skeptic, or you were against skepticism of the safety and efficacy of the vaccine. So people who get nervous about the vaccine, but don’t fall into the usual anti-vax camp, which I think there was a significant- Yeah, yeah. Enough number. They’re asking, they’re getting nervous. I mean, especially after the war in Afghanistan or in Iraq, I too was nervous about anything where a lot of money could be made.
(01:56:22):
And you start, you just see how the people who are greedy, they come to the surface all of a sudden. And a lot of them that run institutions, they’re actually really good human beings. I know a lot of them, but it’s hard to know how those two combine together when there’s hundreds of billions, trillions of dollars to be made. And so that skepticism, I guess the sense was that you weren’t open enough to the skepticism.
Sam Harris (01:56:46):
I understand that people have that sense. I’ll tell you how I thought about it and think about it. One, again, it was a moving target. So there was a point in the timeline where it was totally rational to expect that the vaccines were both working, both they were reasonably safe and that COVID was reasonably dangerous. And that the trade-off for basically everyone was it was rational to get vaccinated, given the level of testing and how many people had been vaccinated before you, given what we were seeing with COVID, right? That that was a forced choice. You’re eventually gonna get COVID, and the question is do you wanna be vaccinated when you do, right?
(01:57:32):
There was a period where that forced choice, where it was just obviously reasonable to get vaccinated, especially because there was every reason to expect that while it wasn’t a perfectly sterilizing vaccine, it was going to knock down transmission a lot, and that matters. And so it wasn’t just a personal choice. You were actually being a good citizen when you decided to run whatever risk you were gonna run to get vaccinated, because there are people in our society who actually can’t get vaccinated. I mean, I know people who can’t take any vaccines. They’re so allergic to, I mean, they, in their own person, seem to justify all of the fears of the anti-vax cult. I mean, it’s like they’re the kind of person who Robert Kennedy Jr. can point to and say, see, vaccines will fucking kill you, right? Because of the experience, and we’re still, I know people who have kids who fit that description, right? So we should all feel a civic responsibility to be vaccinated against egregiously awful and transmissible diseases for which we have relatively safe vaccines to keep those sorts of people safe.
Lex Fridman (01:58:43):
And there was a period of time when it was thought that the vaccine could stop transmission.
Sam Harris (01:58:47):
Yes, and so again, all of this has begun to shift. I don’t think it has shifted as much as Brett Weinstein thinks it’s shifted, but yes, there are safety concerns around the mRNA vaccines, especially for young men, right? As far as I know, that’s the purview of actual heightened concern. But also, there’s now a lot of natural immunity out there, a lot of, basically everyone who was gonna get vaccinated has gotten vaccinated. The virus has evolved to the point in this context where it seems less dangerous. You know, again, I’m going more on the seemings than on research that I’ve done at this point, but I’m certainly less worried about getting COVID. I’ve had it once, I’ve been vaccinated. So you ask me now, how do I feel about getting the next booster?
(01:59:47):
I don’t know that I’m going to get the next booster, right? So I was somebody who was waiting in line at four in the morning, hoping to get some overflow vaccine when it was first available. And that was, at that point, given what we knew, or given what I thought I knew based on the best sources I could consult and based on anecdotes that were too vivid to ignore, both data and personal experience, it was totally rational for me to want to get that vaccine as soon as I could.
(02:00:22):
And now, I think it’s totally rational for me to do a different kind of cost-benefit analysis and wonder, listen, do I really need to get a booster? How many of these boosters am I going to get for the rest of my life, really? And how safe is the mRNA vaccine for a man of my age? And do I need to be worried about myocarditis? All of that is completely rational to talk about now. My concern is that at every point along the way, I was the wrong person, and Brett Weinstein was the wrong person, and there’s many other people I could add to this list, to have strong opinions about any of this stuff.
Lex Fridman (02:01:06):
I just disagree with that. I think, yes, in theory, I agree 100%, but I feel like experts failed at communicating. Not at doing- They did. And I just feel like you and Brett Weinstein actually have the tools with the internet, given the engine you have in your brain of thinking for months at a time, deeply about the problems that face our world, that you actually have the tools to do pretty good thinking here. The problem I have with experts-
Sam Harris (02:01:36):
But there would be deference to experts
Lex Fridman (02:01:38):
and pseudo-experts behind all of that. Well, the papers, you would stand on the shoulders of giants, but you can surf those shoulders better than the giants themselves, it seems.
Sam Harris (02:01:45):
Yeah, but I knew we were gonna disagree about that. I saw his podcast where he brought on these experts who had, many of them, had the right credentials, but for a variety of reasons, they didn’t pass the smell test for me. One larger problem, and this goes back to the problem of how we rely on authority in science, is that you can always find a PhD or an MD to champion any crackpot idea, right? I mean, it is amazing, but you could find PhDs and MDs who would sit up there in front of Congress and say that they thought smoking was not addictive, you know, or that it was not harmful to, there was no direct link between smoking and lung cancer. You could always find those people, and you could, and…
(02:02:31):
But, you know, some of the people Brett found were people who had obvious tells, to my point of view, to my eye, and I saw them on, some of the same people were on Rogan’s podcast, right? And it’s hard, because if a person does have the right credentials, and they’re not saying something floridly mistaken, and we’re talking about something where they’re genuine unknowns, right? Like, how much do we know about the safety of these vaccines, right? It’s, at that point, not a whole hell of a lot. I mean, we have no long-term data on mRNA vaccines.
(02:03:09):
But to confidently say that millions of people are gonna die because of these vaccines, and to confidently say that ivermectin is a panacea, right, ivermectin is the thing that prevents COVID, right? There was no good reason to say either of those things at that moment. And so, given that that’s where Brett was, I felt like there was just no, there was nothing to debate. We’re both the wrong people to be getting into the weeds on this. We’re both gonna defer to our chosen experts. His experts look like crackpots to me, and, or at least the ones who are most vociferous on those edgiest points, it seemed most.
Lex Fridman (02:03:49):
And your experts seem like, what is the term? Mask hysteria, I forgot the term.
Sam Harris (02:03:53):
Well, no, but it’s like with climate science. I mean, this old, it’s received as a canard in half of our society now, but the claim that 97% of climate scientists agree that human-caused climate change is a thing, right? So do you go with the 97% most of the time, or do you go with the 3% most of the time?
(02:04:16):
It’s obvious you go with the 97% most of the time for anything that matters. It’s not to say that the 3% are always wrong. Again, there are, things get overturned. And yes, as you say, and I’ve spent much more time worrying about this on my podcast than I’ve spent worrying about COVID, our institutions have lost trust for good reason, right? And it’s an open question whether we can actually get things done with this level of transparency and pseudo-transparency given our information ecosystems. Like, can we fight a war, really fight a war that we may have to fight, like the next Nazis? Can we fight that war when everyone with an iPhone is showing just how awful it is that little girls get blown up when we drop our bombs, right? Like, could we as a society do what we might have to do to actually get necessary things done when we’re living in this panopticon of just, you know, everyone’s a journalist, right? Everyone’s a scientist, everyone’s an expert, everyone’s got direct contact with the facts or a semblance of the facts.
Lex Fridman (02:05:32):
I don’t know. I think yes, and I think voices like yours are exceptionally important, and I think there’s certain signals you send in your ability to steal me on the other side, in your empathy, essentially. So that’s the fight, that’s the mechanism by which you resist the dogmatism of this binary thinking. And then if you become a trusted person that’s able to consider the other side, then people will listen to you as the aggregator, as the communicator of expertise. Because the virologists haven’t been able to be good communicators. I still, to this day, don’t really know what is the, what am I supposed to think about the safety and efficacy of the vaccines today, as it stands today? What are we supposed to think? What are we supposed to think about testing? What are we supposed to think about the effectiveness of masks or lockdowns?
(02:06:29):
Where’s the great communicators on this topic that consider all the other conspiracy theories, all the communication that’s out there, and actually aggregate it together and be able to say this is actually what’s most likely the truth. And also some of that has to do with humility, epistemic humility, knowing that you can’t really know for sure, just like with depression. You can’t really know for sure. Where’s the, I’m not seeing those communications being effectively done, even still today.
Sam Harris (02:07:01):
Well, the jury is still out on some of it, and again, it’s a moving target. And some of it, I mean, it’s complicated. Some of it’s a self-fulfilling dynamic where like, so like lockdowns, in theory lockdowns, a lockdown would work if we could only do it, but we can’t really do it. And there’s a lot of people who won’t do it because they’re convinced that it’s, this is the totalitarian boot, you know, and finally on the neck of the good people who are always having their interests produced by the elites, right? So like this is, if you have enough people who think the lockdown for any reason in the face of any conceivable illness is just code for the new world order coming to fuck you over and take your guns, right? Okay, you have a society that is now immune to reason, right? Because there are absolutely certain pathogens that we should lock down for next time, right? And it was completely rational in the beginning of this thing to lock down, given or to attempt to lock down, we never really locked down, to attempt some semblance of a lockdown just to quote, bend the curve, to spare our healthcare system, given what we were seeing happening in Italy, right? Like that moment was not hard to navigate, at least in my view, it was obvious at the time. In retrospect, my views on that haven’t changed, except for the fact that I recognize maybe it’s just impossible, be given the nature of people’s response to that kind of demand, right? We live in a society that’s just not gonna lock down.
Lex Fridman (02:08:45):
Unless the pandemic is much more deadly.
Sam Harris (02:08:48):
Right, so that’s a point I made, which was maliciously clipped out from some other podcast where someone’s trying to make it look like I wanna see children die. Like it’s a pity more children didn’t die from COVID, right? This is actually the same person who, and that’s the other thing that got so poisoned here. It’s like that person, this psychopath or effective psychopath who’s creating these clips of me on podcasts, the second clip of me seeming to say that I wish more children died during COVID, but it was so clear in context what I was saying that even the clip betrayed the context, so it didn’t actually work. This psycho, and again, I don’t know whether he actually is a psychopath, but he’s behaving like one because of the incentives of Twitter. This is somebody who Brett signal boosted as a very reliable source of information, right?
(02:09:39):
He kept retweeting this guy at me, against me, right? And this guy, at one glance, I knew how unreliable this guy was, right? But I think I’m not at all sad. One thing I think I did wrong, one thing that I do regret, one thing I have not sorted out for myself is how to navigate the professional and personal pressure that gets applied at this moment where you have a friend or an acquaintance or someone you know who’s behaving badly in public or behaving badly, behaving in a way that you think is bad in public. And they have a public platform where they’re influencing a lot of people, and you have your own public platform where you’re constantly getting asked to comment on what this friend or acquaintance or colleague is doing.
(02:10:41):
I haven’t known what I think is ethically right about the choices that seem forced on us at moments like this. Like, I’ve criticized you in public about your interview with Kanye. Now, in that case, I reached out to you in private first and told you exactly what I thought. And then when I was gonna get asked in public or when I was touching that topic on my podcast, I more or less said the same thing that I said to you in private, right? Now, that was how I navigated that moment. I did the same thing with Elon, at least at the beginning.
(02:11:19):
You know, we have maintained good vibes, which is not what I-
Lex Fridman (02:11:25):
And- Not that- Elon, but- I don’t think, I disagree with you, because good vibes in the moment, there’s a deep core of good vibes that persists through time between you and Elon. And I would argue probably between some of the other folks you mentioned.
Sam Harris (02:11:39):
But I think with Brett, I failed to reach out in private to the degree that I should have. And we never really had a… We had tried to set up a conversation in private that never happened, but there was some communication, but it would have been much better for me to have made more of an effort in private than I did before it spilled out into public. And I would say that’s true with other people as well.
Lex Fridman (02:12:06):
What kind of interaction in private do you think you should have with Brett? Because my case would be beforehand, and now still. The case I would like, and this part of the criticism you sent my way, maybe it’s useful to go to that direction. Actually, let’s go to that direction, because I think I disagree with your criticism, as you stated publicly, but this is very- You’re talking about your interview with Connie? Yeah, yeah, yeah. The thing you criticized me for is actually the right thing to do with Brett. Okay, you said Lex could have spoken with Connie in such a way as to have produced a useful document. He didn’t do that, because he has a fairly naive philosophy about the power of love.
Sam Harris (02:12:47):
Let’s see if you can maintain that philosophy in the presence of- Let’s go.
Lex Fridman (02:12:51):
Criticism, yeah. No, it’s beautiful. He seemed to think that if he just got through the minefield to the end of the conversation, where the two of them still were feeling good about one another, and they can hug it out, that would be, by definition, a success. So let me make the case for this power of love philosophy, right? And first of all, I love you, Sam. You’re still an inspiration and somebody I deeply admire. Okay. Back at you. To me, in the case of Kanye, it’s not only that you get to the conversation and have hugs, it’s that the display that you’re willing to do that has power. So even if it doesn’t end in hugging, the actual, the turning the other cheek, the act of turning the other cheek itself communicates, both to Kanye later and to the rest of the world, that we should have empathy and compassion towards each other. There’s power to that. Maybe that is naive, but I believe in the power of that. So it’s not that I’m trying to convince Kanye that some of his ideas are wrong, but I’m trying to illustrate that just the act of listening and truly trying to understand the human being, that opens people’s minds to actually questioning their own beliefs more. It takes them out of the dogmatism, deescalates the kind of dogmatism that I’ve been seeing. So in that sense, I would say the power of love is the philosophy you might apply to Brett, because the right conversation you have in private is not about, hey, listen, the experts you’re talking to, they seem credentialed, but they’re not actually as credentialed as they’re illustrating, they’re not grounding their findings in actual meta-analyses and papers and so on, like making a strong case. Like, what are you doing? This is gonna get a lot of people in trouble. But instead, just saying, like being a friend in the dumbest of ways, being like, respectful, sending love their way, and just having a conversation outside of all of this. Like basically showing that like, removing the emotional attachment to this debate, even though you are very emotionally attached, because in the case of COVID specifically, there is a very large number of lives at stake. But removing all of that, and remembering that you have a friendship.
Sam Harris (02:15:25):
Yeah, well, so I think these are highly non-analogous cases, right? So your conversation with Kanye misfired, from my point of view, for a very different reason. It has to do with Kanye. I mean, so Kanye, I don’t know, I’ve never met Kanye, so obviously I don’t know him. But I think he’s either obviously in the midst of a mental health crisis, or he’s a colossal asshole, or both. I mean, actually those aren’t mutually exclusive. So one of three possibilities, he’s either mentally ill, he’s an asshole, or he’s mentally ill and an asshole.
Lex Fridman (02:16:04):
I think all three of those possibilities are possible for the both of us as well.
Sam Harris (02:16:08):
No, I would argue none of those are likely for either of us. But not to say we don’t have our moments, but so the reason not to talk to Kanye, so I think you should have had the conversation you had with him in private, that’s great. And I’ve got no criticism of what you said, had it been in private. In public, I just thought you’re not doing him a favor. If he’s mentally ill, right, he’s in the middle of a manic episode, or I’m not a clinician, but I’ve heard it said of him that he is bipolar, you’re not doing him a favor sticking a mic in front of him and letting him go off on the Jews or anything else, right?
(02:16:55):
We know what he thought about the Jews, we know that there’s not much illumination that’s gonna come from him on that topic. And if it is a symptom of his mental illness that he thinks these things, well, then you’re not doing him a favor making that even more public. If he’s just an asshole and he’s just an anti-Semite, an ordinary garden variety anti-Semite, well, then there’s also not much to say unless you’re really gonna dig in and kick the shit out of him in public. And I’m saying you can do that with love. I mean, that’s the other thing here is that I don’t agree that compassion and love always have this patient embracing acquiescent face, right?
(02:17:42):
They don’t always feel good to the recipient, right? There is a sort of wisdom that you can wield compassionately in moments like that where someone’s full of shit and you just make it absolutely clear to them and to your audience that they’re full of shit. And there’s no hatred being communicated. In fact, you could just, it’s like, listen, I’m gonna do everyone a favor right now and just take your foot out of your mouth. And the truth is, I just wouldn’t have aired the conversation. Like, I just don’t think it was a document that had to get out there, right? I get that many people, this is not a signal you’re likely to get from your audience, right? Like, I get that many people in your audience thought, oh my God, that’s awesome. You’re talking to Kanye and you’re doing it in Lex style, where it’s just love, and you’re not treating him like a pariah. And you’re holding this tension between he’s this creative genius, who is work we love, and yet he’s having this moment that’s so painful. And what a tightrope walk. And I get that maybe 90% of your audience saw it that way.
(02:18:45):
They’re still wrong. And I still think that was unbalanced, not a good thing to put out into.
Lex Fridman (02:18:50):
You don’t think it opens up the mind and heart of people that listen to that? Just have it.
Sam Harris (02:18:54):
Seeing a person. If it does, it’s opening up in the wrong direction where just gale force nonsense is coming in, right? I think we should have an open mind and an open heart, but there’s some clear things here that we have to keep in view. One is, the mental illness component is its own thing. I don’t pretend to understand what’s going on with him, but insofar as that’s the reason he’s saying what he’s saying, do not put this guy on camera and let.
Lex Fridman (02:19:23):
Sorry, on that point, real quick, I had a bunch of conversation with him offline, and I didn’t get a sense of mental illness. That’s why I chose to sit down. And I didn’t get, I mean, mental illness is such a.
Sam Harris (02:19:37):
But when he shows up in a gimp hood on Alex Jones’s podcast, I mean, either that’s more genius performance in his world,
Lex Fridman (02:19:46):
or he’s unraveling further. I wouldn’t put that under mental illness. I think there’s another conversation to be had about how we treat artists. Right. Because they’re weirdos.
(02:20:01):
They’re very, I mean, taking words from Kanye as if he’s like Christopher Hitchens or something like that, like very eloquent, researched, written many books on history, on politics, on geopolitics, on psychology. Kanye didn’t do any of that. He’s an artist just spouting off. And so there’s a different style of conversation and a different way to treat the words that are coming out.
Sam Harris (02:20:30):
Coming out of his mouth. Let’s leave the mental illness aside. So if we’re gonna say that there’s no reason to think he’s mentally ill, and this is just him being creative and brilliant and opinionated, well, then that falls into the asshole bucket for me. It’s like, then he’s someone, and honestly, the most offensive thing about him in that interview, from my point of view, is not the antisemitism, which we can talk about, because I think there are problems just letting him spread those memes as well. But the most offensive thing is just how delusionally egocentric he is, or was coming off in that interview and in others. Like he has an estimation of himself as this omnibus genius, not only to rival Shakespeare, to exceed Shakespeare, right? I mean, it’s like he is the greatest mind that has ever walked among us.
(02:21:19):
And he’s more or less explicit on that point, and yet he manages to talk for hours without saying anything actually interesting or insightful or factually illuminating, right? So it’s complete delusion of a very Trumpian sort.
(02:21:31):
It’s like when Trump says he’s a genius who understands everything, but nobody takes him seriously, and one wonders whether Trump takes himself seriously. Kanye seems to believe his own press. He actually thinks he’s just a colossus, and he may be a great musician. I’m not, it’s certainly not my wheelhouse to compare him to any other musicians, but one thing that’s patently obvious from your conversation is he’s not who he thinks he is intellectually or ethically or in any other relevant way. And so when you couple that to the antisemitism he was spreading, which was genuinely noxious and ill-considered and has potential knock-on effects in the black community. I mean, there’s an ambient level of antisemitism in the black community that is worth worrying about and talking about anyway. There’s a bunch of guys playing the knockout game in Brooklyn just punching Orthodox Jews in the face. And I think letting Kanye air his antisemitism that publicly only raises the likelihood of that
Lex Fridman (02:22:46):
rather than diminishes it. I don’t know, so let me say just a couple of things. So one, my belief at the time was it doesn’t, it decreases it. Showing empathy while pushing back decreases the likelihood of that. It might on the surface look like it’s increasing it, but that’s simply because the antisemitism or the hatred in general is brought to the surface and then people talk about it. But I should also say that you’re one of the only people that wrote to me privately criticizing me. And out of the people I really respect and admire, and that was really valuable, painful, because I had to think through it for a while. And it still haunts me because the other kind of criticism I got a lot of, people basically said, thinks towards me based on who I am that they hate me. Just- You mean antisemitic things or that you- Yeah, antisemitic things. I just hate the word antisemitic. It’s like racist.
Sam Harris (02:23:45):
Well, but here’s the reality. So I’m someone, so I’m Jewish, although obviously not religious. I have never taken, you know, I’ve been a student of the Holocaust, obviously. I know a lot about that and there’s reason to be a student of the Holocaust. But in my lifetime and in my experience, I have never taken antisemitism very seriously. I have not worried about it. I have not made a thing of it. I’ve done exactly one podcast on it. I had Barry Weiss on my podcast when her book came out.
(02:24:22):
But it really is a thing. And it’s something we have to keep an eye on societally, because it’s a unique kind of hatred, right? It’s unique in that it seems, it’s knit together with, it’s not just ordinary racism. It’s knit together with lots of conspiracy theories that never seem to die out. It can by turns equally animate the left and the right politically. I mean, what’s so perverse about antisemitism, look in the American context.
(02:24:58):
With the far right, you know, with white supremacists, Jews aren’t considered white. So they hate us in the same spirit in which they hate black people or brown people or anyone who’s not white. But on the left, Jews are considered extra white. I mean, we’re the extra beneficiaries of white privilege, right? And in the black community, that is often the case, right? We’re a minority that has thrived. And it seems to stand as a counterpoint to all of the problems that other minorities suffer, in particular, African-Americans in the American context.
(02:25:34):
And yeah, Asians are now getting a little bit of this, you know, like the model minority issue. But Jews have had this going on for centuries and millennia, and it never seems to go away. And again, this is something that I’ve never focused on, but this has been at a slow boil for as long as we’ve been alive, and there’s no guarantee it can’t suddenly become much, much uglier than we have any reason to expect it to become, even in our society.
(02:26:07):
And so there’s kind of a special concern at moments like that where you have an immensely influential person in a community who already has a checkered history with respect to their own beliefs about the Jews and the conspiracies and all the rest. And he’s just messaging, you know, not especially fully opposed by you and anyone else who’s given him the microphone at that moment to the world. And so that, you know, made my Spidey sense tingle.
Lex Fridman (02:26:40):
Yeah, it’s complicated. The stakes are very high. And as somebody that’s been obviously family and also reading a lot about World War II, and just this whole period, it was a very difficult conversation. But I believe in the power, especially given who I am of not always, but sometimes, often turning the other cheek.
Sam Harris (02:27:03):
Oh yeah, and again, things change when they’re for public consumption. You know, it’s like, I mean, the cut for me that, you know, has just, the use case I keep stumbling upon is the kinds of things that I will say on a podcast like this, or if I’m giving a public lecture, versus the kinds of things I will say at dinner with strangers or with friends. Like if you’re in an elevator, like if I’m in an elevator with strangers, I do not feel, and I hear someone say something stupid, I don’t feel an intellectual responsibility to turn around in the confines of that space with them and say, listen, that thing you just said about X, Y, or Z is completely false, and here’s why, right? But if somebody says it in front of me, in front of me on some public dais where I’m actually talking about ideas, that’s when, you know, there’s a different responsibility that comes online. The question is how you say it, how you say it. Or even whether you say anything in those, I mean, there are moments, there are definitely moments to privilege civility or just to pick your battles. I mean, sometimes it’s just not worth it to get into it with somebody out in real life.
Lex Fridman (02:28:14):
I just believe in the power of empathy both in the elevator and when a bunch of people are listening, that when they see you willing to consider another human being’s perspective, it just gives more power to your words after.
Sam Harris (02:28:37):
Well, yeah, but until it doesn’t, because you can extend charity too far, right? Like it can be absolutely obvious what someone’s motives really are, and they’re dissembling about that, right? And so then you’re taking at face value their representations, begins to look like you’re just being duped and you’re not actually doing the work of putting pressure on a bad actor. And again, the mental illness component here makes it very difficult to think about what you should or shouldn’t have said to Kanye.
Lex Fridman (02:29:11):
So I think the topic of platforming is pretty interesting. Like what’s your view on platforming controversial people? Let’s start with the old, would you interview Hitler on your podcast? And how would you talk to him? Oh, and follow-up question. Would you interview him in 1935, 41, and then like 45?
Sam Harris (02:29:37):
Well, I think we have an uncanny valley problem with respect to this issue of whether or not to speak to bad people, right? So if a person is sufficiently bad, right? If they’re all the way out of the valley, then you can talk to them and it’s just totally unproblematic to talk to them because you don’t have to spend any time signaling to your audience that you don’t agree with them. And if you’re interviewing Hitler, you don’t have to say, listen, I just got to say before we start, I don’t agree with the whole genocide thing, and I just think you’re killing mental patients and vans and all that. That was all bad, that’s a bad look, Adolf. It can go without saying that you don’t agree with this person and you’re not platforming them to signal boost their views. You’re just trying to, if they’re sufficiently evil, you can go into it very much as an anthropologist would.
(02:30:35):
You just want to understand the nature of evil, right? You just want to understand this phenomenon, like how is this person who they are, right? And that strikes me as a intellectually interesting and morally necessary thing to do, right? So yes, I think you always interview Hitler. Wait, wait, wait, wait, wait, wait, wait, wait, wait. Well, when you know, once he’s Hitler. But when do you know it?
Lex Fridman (02:31:02):
Once he’s legitimately Hitler. But when do you know it? Is genocide really happening?
Sam Harris (02:31:06):
Yeah, yeah, yeah. It’s like 42, 43? No, no, no, if you’re on the cusp of it where it’s just he’s someone who’s gaining power and you don’t want to help facilitate that, then there’s a question of whether you can undermine him while pushing back against him in that interview, right? So there are people I wouldn’t talk to just because I don’t want to give them oxygen and I don’t think that in the context of my interviewing them I’m going to be able to take the wind out of their sails at all, right? So it’s like, for whatever, either because an asymmetric advantage, because I just know that they can do something within the span of an hour that I can’t correct for, you know, it’s like they can light many small fires and it just takes too much time to put them out.
Lex Fridman (02:31:52):
That’s more like on the topic of vaccines, for example, having a debate on the efficacy of vaccines.
Sam Harris (02:31:56):
Yeah. It’s not that I don’t think sunlight is usually the best disinfectant, I think it is. You know, even these asymmetries aside, I mean, it is true that a person can always make a mess faster than you can clean it up, right? But still there are debates worth having even given that limitation. And they’re the right people to have those specific debates. And there’s certain topics where, you know, I’ll debate someone just because I’m the right person for the job and it doesn’t matter how messy they’re going to be. It’s just worth it because I can make my points land, at least to the right part of the audience.
Lex Fridman (02:32:34):
So some of it is just your own skill and competence and also interest in preparing correctly?
Sam Harris (02:32:39):
Well, yeah, yeah, and the nature of the subject matter. But there are other people who just by default, I would say, well, there’s no reason to give this guy a platform. And there are also people who are so confabulatory that they’re making such a mess with every sentence that insofar as you’re even trying to interact with what they’re saying, you’re by definition going to fail and you’re going to seem to fail to a sufficiently large uninformed audience where it’s going to be a net negative for the cause of truth, no matter how good you are. So like, for instance, I think talking to Alex Jones on any topic for any reason is probably a bad idea because I just think he’s just neurologically wired to just utter a string of sentences. He’ll get 20 sentences out, each of which contains more lies than the last.
(02:33:43):
And there’s not time enough in the world to run down, and certainly not time enough in the span of a conversation, to run down each of those leads to bedrock so as to falsify it. I mean, he’ll just make shit up. Or make shit up and then weave it in with half-truths and micro-truths that give some semblance of credibility to somebody out there. I mean, apparently millions of people out there. And there’s just no way to untangle that in real time with him.
Lex Fridman (02:34:17):
I have noticed that you have an allergic reaction to confabularitization.
Sam Harris (02:34:24):
Yeah, confabulation.
Lex Fridman (02:34:25):
Confabulation. That if somebody says something a little micro-untruth, it really stops your brain.
Sam Harris (02:34:34):
Here I’m not talking about micro-untruths, I’m just talking about making up things out of whole cloth. If someone says something, well, what about, and then the thing they put at the end of that sentence is just a set of pseudo-facts, right, that you can’t possibly authenticate or not in the span of that conversation. Whether it’s about UFOs or anything else, right?
(02:35:00):
They will seem to make you look like an ignoramus when, in fact, everything they’re saying is specious, right, whether they know it or not. I mean, there’s some people who are just crazy, there’s some people who are just bullshitting and they’re not even tracking whether it’s true, it just feels good. And there’s some people who are consciously lying about things.
Lex Fridman (02:35:20):
But don’t you think there’s just a kind of jazz masterpiece of untruth that you should be able to just wave off by saying like, well, none of that is backed up by any evidence, and just almost like take it to the humor place?
Sam Harris (02:35:34):
And then- But the thing is, the place I’m familiar with doing this and not doing this is on specific conspiracies like 9-11 truth, right? Like the 9-11, so I, because of my, because of what 9-11 did to my intellectual life, I mean, it really just, you know, it sent me down a path for the better part of a decade. Like I became a critic of religion.
(02:36:00):
When I, I don’t know if I was ever gonna be a critic of religion, right? Like, but that, like, it happened to be in my wheelhouse because I had spent so much time studying religion on my own, and I was also very interested in the underlying spiritual concerns of every religion, and so I was, I devoted more than a full decade of my life to just, you know, what is real here? What is possible? What is the nature of subjective reality, and how does it relate to reality at large, and is there anything to, you know, who was someone like Jesus or Buddha, and are these people frauds, or are they, are these just myths, or is there really a continuum of insight to be had here that is interesting? So I spent a lot of time on that question through my 20, the full decade of my 20s.
Lex Fridman (02:36:55):
And that was launched in part by 9-11 Truth Hour?
Sam Harris (02:36:60):
No, but then when 9-11, I had spent all this time reading religious books, understanding, empathically understanding the motivations of religious people, right? Knowing just how fully certain people believe what they say they believe, right? So I took religious convictions very seriously, and then people started flying planes into our buildings, and I, so I knew that there was something to be said about that. Allegedly. The core doctrines of Islam, yeah, exactly.
(02:37:26):
So I went down, so that was, that became my wheelhouse for a time, you know, terrorism and jihadism and related topics. And so the 9-11 truth conspiracy thing kept, you know, getting aimed at me, and the question was, well, do I wanna debate these people?
Lex Fridman (02:37:47):
Right? Yeah, Alex Jones, perhaps.
Sam Harris (02:37:49):
Yeah, I mean, yeah, so Alex Jones, I think, was an early purveyor of it, although I don’t think I knew who he was at that point. And so, and privately, I had some very long debates with people who, you know, one person in my family went way down that rabbit hole, and I just, you know, every six months or so, I’d literally write the two-hour email, you know, that would try to deprogram him, you know, however ineffectually. And so I went back and forth for years on that topic with, in private, with people. But I could see the structure of the conspiracy. I could see the nature of how impossible it was to play whack-a-mole sufficiently well so as to convince anyone of anything who was not seeing the problematic structure of that way of thinking. I mean, it’s not actually a thesis. It’s a proliferation of anomalies that don’t, you can’t actually connect all the dots that are being pointed to. They don’t connect in a coherent way. They’re incompatible theses that are not, and their incompatibility is not being acknowledged.
(02:39:01):
They’re running this algorithm of things are, things are never what they seem. There’s always malicious conspirators doing things perfectly. We see all, we see evidence of human incompetence everywhere else. No one can tie their shoes expertly anywhere else.
(02:39:21):
But over here, people are perfectly competent. They’re perfectly concealing things. Like thousands of people are collaborating, inexplicably, I mean, incentivized by what, who knows. They’re collaborating to murder thousands of their neighbors and no one is breathing a peep about it. No one’s getting caught on camera. No one’s breathed a word of it to a journalist. And so I’ve dealt with that style of thinking and I know what it’s like to be in the weeds of a conversation like that. And the person will say, okay, well, but what do you make of the fact that all those F-16s were flown 800 miles out to sea on the morning of 9-11 to do an exercise that hadn’t even been scheduled for that day, but it was, and now all of these are, I dimly recall some thesis of that kind, but I’m just making these things up now, right? So like that detail hadn’t even been scheduled for that day, it was inexplicably run that day.
(02:40:23):
How long would it take to track that down, right? The idea that this is anomalous, like there was a F-16 exercise run and it wasn’t even supposed to be run that day, right? Someone like Alex Jones, their speech pattern is to pack as much of that stuff in as possible at the highest velocity that the person can speak. And unless you’re knocking down each one of those things to that audience, you appear to just be uninformed. You appear to just not be, wait a minute, he didn’t know about the F-16s? Yeah.
(02:41:01):
True. He doesn’t know about Project Mockingbird? You haven’t heard about Project Mockingbird? I just made up Project Mockingbird, I don’t know what it is, but that’s the kind of thing that comes tumbling out in a conversation like that. That’s the kind of thing, frankly, I was worried about in the COVID conversation, because not that someone like Brett would do it consciously, but someone like Brett is swimming in a sea of misinformation on social, living on Twitter, getting people sending the blog post and the study from the Philippines that showed that in this cohort, Ivermectin did X, right?
(02:41:39):
To actually run anything to ground, you have to actually do the work journalistically and scientifically and run it to ground. So for some of these questions, you actually have to be a statistician to say, okay, they used the wrong statistics in this experiment. Now, yes, we could take all the time to do that, or we could at every stage along the way in a context where we have experts we can trust go with what 97% of the experts are saying about X, about the safety of mRNA, about the transmissibility of COVID, about whether to wear masks or not wear masks. And I completely agree that that broke down unacceptably over the last few years. But I think that’s largely social media and blogs and the efforts of podcasters and substack writers were not just a response to that. It was a, I think it was a symptom of that and a cause of that, right? And I think we’re living in an environment where people, we’ve basically, we have trained ourselves not to be able to agree about facts on any topic, no matter how urgent, right? What’s flying in our sky? What’s happening in Ukraine? Is Putin just denazifying Ukraine? I mean, there are people who we respect who are spending time down that particular rabbit hole. Like this is, maybe there are a lot of Nazis in Ukraine and that’s the real problem, right?
(02:43:35):
Maybe Putin’s not the bad actor here, right? How much time do I have to spend empathizing with Putin to the point of thinking, well, maybe Putin’s got a point and it’s like, what about the polonium and the nerve agents and the killing of journalists and the Navalny? And like, does that count? Well, no, listen, I’m not paying so much attention to that because I’m following all these interesting people on Twitter and they’re giving me some pro-Putin material here and there are some Nazis in Ukraine. It’s not like there are no Nazis in Ukraine. How am I gonna weight these things? I think people are being driven crazy by Twitter.
Lex Fridman (02:44:15):
Yeah, but you’re kind of speaking to conspiracy theories that pollute everything and then, but every example you gave is kind of a bad faith style of conversation.
Sam Harris (02:44:27):
But it’s not necessarily knowingly bad faith by, I mean, the people who are worried about Ukrainian Nazis, to my, I mean, they’re some of the same people. They’re the same people who are worried about ivermectin got suppressed. Like, ivermectin is really a panacea, but it got suppressed for, because no one could make billions on it. It’s the same, it’s literally, in many cases, the same people and the same efforts to unearth those.
Lex Fridman (02:44:59):
You’re saying it’s very difficult to have conversations with those kinds of people. What about a conversation with Trump himself? Would you do a podcast with Trump?
Sam Harris (02:45:09):
No, I don’t think so. I don’t think I’d be learning anything about him. It’s like with Hitler, and I’m not comparing Trump to Hitler, but Clipse guy, here’s your chance. You got this one. With certain world historical figures, I would just feel like, okay, this is an opportunity to learn something that I’m not gonna learn. I think Trump is among the most superficial people we have ever laid eyes on, right? Like, he is in public view, right? And I’m sure there’s some distance between who he is in private and who he is in public, but it’s not gonna be the kind of distance that’s gonna blow my mind. And I think, so I think the liability of, so for instance, I think Joe Rogan was very wise not to have Trump on his podcast. I think all he would have been doing is, he would have put himself in a situation where he couldn’t adequately contain the damage Trump was doing, and he was just gonna make Trump seem cool to a whole new, you know, a potentially new cohort of his massive audience, right?
(02:46:19):
I mean, they would have had a lot of laughs. Trump’s funny. I mean, the entertainment value of things is so influential. I mean, there was that one debate where Trump, you know, got a massive laugh on his line, you know, only Rosie O’Donnell, right?
(02:46:41):
And the truth is we’re living in a political system where if you can get a big laugh during a political debate, you win. It doesn’t matter who you are. That’s the level of, you know, it doesn’t matter how uninformed you are. It doesn’t matter that half the debate was about what the hell we should do about, you know, the threat of nuclear war or anything else. It’s, we’re monkeys, right? And we like to laugh.
Lex Fridman (02:47:08):
Yeah. Well, because you brought up Joe. He’s somebody like you I look up to. I’ve learned a lot from him because I think who he is privately as a human being, also his, he’s kind of the voice of curiosity to me. He inspired me that, so unending, open-minded curiosity, much like you are the voice of reason. They recently had a podcast, Joe had recently had a podcast with Jordan Peterson and he had brought you up saying they still have a hope for you.
Sam Harris (02:47:39):
Mm-hmm, yeah. Any chance- I saw that clip, yeah.
Lex Fridman (02:47:42):
Any chance you talk to Joe again and reinvigorate your friendship?
Sam Harris (02:47:47):
Yeah, well, I reached out to him privately when I saw that.
Lex Fridman (02:47:51):
Did you use the power of love?
Sam Harris (02:47:53):
Joe knows I love him and consider him a friend, right, so there’s no issue there. He also knows I’ll be happy to do his podcast when we get that together. So there’s no, I’ve got no policy of not talking to Joe or not doing his podcast. I mean, I think we got a little sideways along these same lines where we’ve talked about Brett and Elon and other people. But it was never to that degree with Joe because Joe’s in a very different lane, right? He’s, and consciously so. I mean, Joe is a stand-up comic who interviews, who just is interested in everything, interviews the widest conceivable variety of people and just lets his interests collide with their expertise or lack of expertise. I mean, he’s, again, it’s a super wide variety of people. He’ll talk about anything and he can always pull the ripcord saying, I don’t know what the fuck I’m saying, I’m a comic, I’m stoned, we just drank too much, right? Like, it’s very entertaining. It’s all in, to my eye, it’s all in good faith. I think Joe is an extraordinarily ethical, good person.
Lex Fridman (02:49:08):
Also doesn’t use Twitter, doesn’t really use Twitter.
Sam Harris (02:49:10):
Right, yeah, yeah, the crucial difference, though, is that because he, an entertainer first, I mean, I’m not saying he’s not smart and doesn’t understand things. I mean, what’s potentially confusing is he’s very smart and he’s also very informed. His full-time job is taught, you know, when he’s not doing stand-up or doing color commentary for the UFC, his full-time job is talking to lots of very smart people and very smart people at great length. So he’s created the Joe Rogan University for himself and he’s gotten a lot of information crammed into his head. So it’s not that he’s uninformed, but he can always, when he feels that he’s uninformed or when it turns out he was wrong about something, he can always pull the ripcord and say, I’m just a comic, we were stoned, it was fun, don’t take medical advice from me, I don’t play a doctor on the internet, right?
(02:50:10):
I can’t quite do that, right? You can’t quite do that, we’re in different lanes. I’m not saying you and I are in exactly the same lane, but for much of Joe’s audience, I’m just this establishment shill who’s just banging on about, you know, the universities and medical journals and it’s not true, but that would be the perception. And as a counterpoint to a lot of what’s being said on Joe’s podcast or, you know, certainly Brett’s podcast on these topics, I can see how they would form that opinion, but in reality, if you listen to me long enough, you hear that I’ve said as much against the woke nonsense as anyone, even any lunatic on the right who can only keep that bright, that bright, shiny object in view, right? So there’s nothing that Candace Owens has said about wokeness that I haven’t said about wokeness so far as she’s speaking rationally about wokeness, but we have to be able to keep multiple things in view, right, if you could only look at the problem of wokeness and you couldn’t acknowledge the problem of Trump and Trumpism and QAnon and the explosion of irrationality that was happening on the right and bigotry that was happening on the right, you were just disregarding half of the landscape and many people took half of the problem in recent years. The last five years is a story of many people taking half of the problem and monetizing that half of the problem and getting captured by an audience that only wanted that half of the problem talked about in that way. And this is the larger issue of audience capture, which is very, I’m sure it’s an ancient problem, but it’s a very helpful phrase that I think comes to us courtesy of our mutual friend, Eric Weinstein.
(02:52:08):
And audience capture is a thing and I believe I’ve witnessed many casualties of it and if there’s anything I’ve been on guard against in my life professionally, it’s been that and when I noticed that I had a lot of people in my audience who didn’t like my criticizing Trump, I really leaned into it and when I noticed that a lot of the other cohort in my audience didn’t like me criticizing the far left and wokeness, they thought I was exaggerating that problem, I leaned into it because I thought those parts of my audience were absolutely wrong and I didn’t care about whether I was gonna lose those parts of my audience. There are people who have created, knowingly or not, there are people who’ve created different incentives for themselves because of how they’ve monetized their podcast and because of the kind of signal they’ve responded to in their audience. And I worry about, Brett would consider this a totally invidious ad hominem thing to say, but I really do worry that that’s happened to Brett. I think, I cannot explain how you do 100, with all the things in the universe to be interested in and of all the things he’s competent to speak intelligently about, I don’t know how you do 100 podcasts in a row on COVID, right, it’s just, it makes no sense.
Lex Fridman (02:53:31):
I think in part audience capture can explain that. I absolutely think it can, yeah. What about, do you, like for example, do you feel pressure to not admit that you made a mistake on COVID or made a mistake on Trump? I’m not saying you feel that way, but do you feel this pressure? So you’ve attacked audience capture within the way you do stuff, so you don’t feel as much pressure from the audience, but within your own ego?
Sam Harris (02:54:00):
I mean, again, the people who think I’m wrong about any of these topics are gonna think, okay, you’re just not admitting that you’re wrong, but now we’re having a dispute about specific facts. There are things that I believed about COVID or worried might be true about COVID two years ago that I no longer believe or I’m not so worried about now and vice versa. I mean, things have flipped, certain things have flipped upside down.
(02:54:36):
The question is, was I wrong? So here’s the cartoon version of it, but this is something I said probably 18 months ago and it’s still true. You know, when I saw what Brett was doing on COVID, let’s call it two years ago, I said, even if he’s right, even if it turns out that ivermectin is a panacea and the mRNA vaccines kill millions of people, he’s still wrong right now. His reasoning is still flawed right now. His facts still suck right now. And his confidence is unjustified now. That was true then, that will always be true then.
(02:55:23):
And not much has changed for me to revisit any of my time points along the way. Again, I will totally concede that if I had teenage boys and their schools were demanding that they be vaccinated with the mRNA vaccine, I would be powerfully annoyed, right? Like I wouldn’t know what I was going to do and I would be doing more research about myocarditis and I’d be badgering our doctors and I would be worried that we have a medical system and a pharmaceutical system and a healthcare system and a public health system that’s not incentivized to look at any of this in a fine-grained way and they just want one blanket admonition to the entire population, just take the shot, you idiots.
(02:56:16):
I view that largely as a result, a panicked response to the misinformation explosion that happened and the populist resistance animated by misinformation that just made it impossible to get anyone to cooperate. So it’s just, part of it is, again, a pendulum swing in the wrong direction. Somewhat analogous to the woke response to Trump and the Trumpist response to woke, right? So a lot of people have just gotten pushed around for bad reasons, but understandable reasons.
(02:56:49):
But it’s, there are caveats to my, things have changed about my view of COVID, but the question is, if you roll back the clock 18 months, was I wrong to want to platform Eric Topol, you know, a very well-respected cardiologist on this topic, or, you know, Nicholas Christakis to talk about the network effects of, you know, whether we should close schools, right? He’s written a book on COVID, he’s, you know, network effects are his wheelhouse as a, both as an MD and as a sociologist.
(02:57:29):
There was a lot that we believed we knew about the efficacy of closing schools during pandemics, right, during the, you know, during the Spanish flu pandemic and others, right? But there’s a lot we didn’t know about COVID. We didn’t know, we didn’t know how negligible the effects would be on kids compared to older people. We didn’t know, like, so.
Lex Fridman (02:57:53):
My problem, I really enjoyed your conversation with Eric Topol, but also didn’t. So he’s one of the great communicators in many ways on Twitter, like distillation of the current data. But he, I hope I’m not overstating it, but there is a bit of an arrogance from him that I think could be explained by him being exhausted by being constantly attacked by conspiracy theory, like anti-vaxxers. To me, the same thing happens with people that start drifting to being right-wing, is to get attacked so much by the left, they become almost irrational and arrogant in their beliefs. And I felt your conversation with Eric Topol did not sufficiently empathize with people that have skepticism, but also did not sufficiently communicate uncertainty we have. So, like, many of the decisions you made, many of the things you were talking about were kind of saying there’s a lot of uncertainty, but this is the best thing we could do now.
Sam Harris (02:58:57):
Well, it was a forced choice. You’re gonna get COVID. Do you wanna be vaccinated when you get it? That was always, in my view, an easy choice. And it’s up until you start breaking apart the cohorts and you start saying, okay, wait a minute, there is this myocarditis issue in young men. Let’s talk about that. Before that story emerged, it was just clear that if it’s not knocking down transmission as much as we had hoped, it is still mitigating severe illness and death.
(02:59:38):
And I still believe that it is the current view of most people competent to analyze the data that we lost something like 300,000 people unnecessarily in the U.S. because of vaccine hesitancy.
Lex Fridman (02:59:54):
But I think there’s a way to communicate with humility about the uncertainty of things that would increase the vaccination rate.
Sam Harris (03:00:01):
I do believe that it is rational and sometimes effective to signal impatience with certain bad ideas, right, and certain conspiracy theories and certain forms of misinformation. I think so. Because it’s just-
Lex Fridman (03:00:19):
I just think it makes you look like a douchebag most times.
Sam Harris (03:00:21):
Well, I mean, certain people are persuadable, certain people are not persuadable, but it’s, no, because there’s not enough, it’s the opportunity cost, not everything can be given a patient hearing. So you can’t have a physics conference and then let people in to just trumpet their pet theories about the grand unified vision of physics when they’re obviously crazy or they’re obviously half crazy, or they’re just not, you know, the people, it’s like you begin to, you begin to get a sense for this when it is your wheelhouse, but there are people who kind of declare their irrelevance to the conversation fairly quickly without knowing that they have done it, right? And the truth is, I think I’m one of those people on the topic of COVID, right? Like I, it’s like, it’s not, it’s never that I felt, listen, I know exactly what’s going on here. I know these mRNA vaccines are safe. I know exactly how to run a lockdown.
(03:01:30):
No, this is a situation where you want the actual pilots to fly the plane, right? We needed experts who we could trust. And insofar as our experts got captured by all manner of thing, I mean, some of them got captured by Trump. Some of them were made to look ridiculous just standing next to Trump while he was bloviating about whatever, that it’s just gonna go away.
(03:01:53):
There’s just 15 people. You know, there’s 15 people in a cruise ship and it’s just gonna go away. There’s gonna be no problem. Or it’s like when he said, he, you know, many of these doctors think I understand this better than them. They’re just amazed at how I understand this. And you’ve got doctors, real doctors, the heads of the CDC and NIH standing around just ashen faced while he’s talking, you know. All of this was deeply corrupting of the public communication of science. And then again, I’ve banged on about the depredations of wokeness. The woke thing was a disaster, right? Still is a disaster. But it doesn’t mean that, but the thing is there’s a big difference between me and Brett in this case. I didn’t do a hundred podcasts on COVID. I did like two podcasts on COVID. The measure of my concern about COVID can be measured in how many podcasts I did on it, right? It’s like once we had a sense of how to live with COVID, I was just living with COVID, right? Like, okay, get vaxxed or don’t get vaxxed. Wear a mask or don’t wear a mask. Travel or don’t travel. Like you’ve got a few things to decide, but my kids were stuck at home on iPads, you know, for too long. I didn’t agree with that. You know, it was obviously not functional. Like I criticized that on the margins, but there was not much to do about it. But the thing I didn’t do is make this my life and just browbeat people with one message or another. We need a public health regime where we can trust what the competent people are saying to us about, you know, what medicines are safe to take. And in the absence of that, craziness is gonna, even in the presence of that, craziness is gonna proliferate given the tools we’ve built. But in the absence of that, it’s gonna proliferate for understandable reasons. And that’s gonna, it’s not gonna be good next time when something orders of magnitude more dangerous hits us. And that’s, I spent, you know, insofar as I think about this issue, I think much more about next time than this time.
Lex Fridman (03:03:59):
Before this COVID thing, you and Brett had some good conversations. I would say we’re friends. What’s your, what do you admire most about Brett outside of all the criticism we’ve had about this COVID topic?
Sam Harris (03:04:13):
Well, I think Brett is very smart and he’s a very ethical person who wants good things for the world. I mean, I have no reason to doubt that. So the fact that we’re on, you know, we’re crosswise on this issue is not, does not mean that I think he’s a bad person. I mean, the thing that worried me about what he was doing, and this was true of Joe and this was true of Elon, this is true of many other people, is that once you’re messaging at scale to a vast audience, you incur a certain kind of responsibility not to get people killed. And I do, I did worry that, yeah, people were making decisions on the basis of the information that was getting shared there. And that’s why I was, I think, fairly circumspect.
(03:05:02):
I just said, okay, give me the center of the fairway expert opinion at this time point and at this time point and at this time point, and then I’m out, right? I don’t have any more to say about this. I’m not an expert on COVID. I’m not an expert on the safety of mRNA vaccines.
(03:05:24):
If something changes so as to become newsworthy, then maybe I’ll do a podcast. So I mean, I just did a podcast on the lab leak, right? I was never skeptical of the lab leak hypothesis. Brett was very early on saying, this is a lab leak, right? At a point where my only position was, who cares if it’s a lab leak, right? Like, the thing we have to get straight is, what do we do given the nature of this pandemic?
Lex Fridman (03:05:51):
But also, we should say that you’ve actually stated that it is a possibility.
Sam Harris (03:05:55):
Oh, yeah. You just said it doesn’t quite matter. The time to figure that out, now, I’ve actually, I have had my podcast guest on this topic change my view of this because one of the guests, Alina Chan, made the point that, no, actually, the best time to figure out the origin of this is immediately, right? Because then you lose touch with the evidence. And I hadn’t really been thinking about that. Like, I didn’t, if you come back after a year, you know, there are certain facts you might not be able to get in hand. But I’ve always felt it didn’t matter for two reasons.
(03:06:30):
One is, we had the genome of the virus and we could design, we’re very quickly design, immediately designing vaccines against that genome. And that’s what we had to do. And then we had to figure out how to vaccinate and to mitigate and to develop treatments and all that. So the origin story didn’t matter. Generically speaking, either origin story was politically inflammatory and made the Chinese look bad. And the Chinese response to this looked bad, whatever the origin story, right? They’re not cooperating.
(03:07:09):
They’re letting, they’re stopping their domestic flights, but letting their international flights go. I mean, it’s just, they were bad actors and they should be treated as such regardless of the origin, right? And, you know, I would argue that the wet market origin is even more politically invidious than the lab leak origin. I mean- Why do you think? Because for lab leak, to my eye, the lab leak could happen to anyone, right? We’re all running, all these advanced countries are running these dangerous labs. That’s a practice that we should be worried about, you know, in general. We know lab leaks are a problem. There’ve been multiple lab leaks of even worse things that haven’t gotten out of hand in this way, but, you know, worse pathogens.
(03:07:55):
We’re wise to be worried about this. And on some level, it could happen to anyone, right? The wet market makes them look like barbarians living in another century. Like, you gotta clean up those wet markets. Like, what are you doing putting a bat on top of a pangolin, on top of a duck? It’s like, get your shit together. So, like, if anything, the wet market makes them look worse, in my view. Now, I’m sure there’s, I’m sure that what they actually did to conceal a lab leak, if it was a lab leak, I mean, all of that’s gonna look odious.
Lex Fridman (03:08:29):
Do you think we’ll ever get to the bottom of that? I mean, one of the big negative, I would say, failures of Anthony Fauci and so on is to be transparent and clear, and just a good communicator about gain-and-functional research, the dangers of that, why it’s a useful way of research, but it’s also dangerous. You know, just being transparent about that, as opposed to just coming off really shady. Of course, the conspiracy theorists and the politicians are not helping, but this just created a giant mess.
Sam Harris (03:09:04):
So, yeah, no, I would agree. So, that exchange with Fauci and Rand Paul that went viral, yeah, I would agree that Fauci looked like he was taking refuge in kind of very lawyered language, and not giving a straightforward account of what we do and why we do it. And so, yeah, I think it looked shady, it played shady, and it probably was shady. I mean, I don’t know how personally entangled he is with any of this, but, yeah, the gain-of-function research is something that I think we’re wise to be worried about, and insofar as I judge myself adequate to have an opinion on this, I think it should be banned, right? Like, probably a podcast I’ll do, you know, if you or somebody else doesn’t do it in the meantime, you know, I would like a virologist to defend it against a virologist who would criticize it. Forget about just the gain-of-function research.
(03:10:12):
I don’t even understand virus hunting at this point. It’s like, I don’t know, I don’t even know why you need to go into a cave to find this next virus that could be circulating among bats that may jump zoonotically to us. Why do that when we can make, when we can sequence in a day and make vaccines in a weekend?
Lex Fridman (03:10:33):
I mean, like, what kind of head start do you think you’re getting? That’s a surprising new thing, how quickly you can develop a vaccine. Exactly. That’s, yeah, that’s really interesting, but the shadiness around lab leak.
Sam Harris (03:10:45):
I think the point I didn’t make about Brett’s style of engaging this issue is people are using the fact that he was early on lab leak to suggest that he was right about ivermectin and about mRNA vaccines and all the rest. Like, no, that’s, none of that connects. And it was possible to be falsely confident, like, you shouldn’t have been confident about lab, no one should have been confident about lab leak early, even if it turns out to be lab leak, right? It was always plausible. It was never definite. It still isn’t definite. Zoonotic is also quite plausible. It certainly was super plausible then. Both are politically uncomfortable. Both at the time were inflammatory to be banging on about when we were trying to secure some kind of cooperation from the Chinese, right? So there’s a time for these things and it’s possible to be right by accident, right? That’s the thing, that is, it matters, your reasoning, the style of reasoning matters whether you’re right or not. You know, it’s like, because your style of reasoning is dictating what you’re gonna do on the next topic.
Lex Fridman (03:12:02):
Sure, but this is a, this multivariate situation here. It’s really difficult to know what’s right on COVID given all the uncertainty, all the chaos, especially when you step outside the pure biology, virology of it and you start to get into policy. It’s really. Yeah, it’s just trade-offs, yeah. Like transmissibility of the virus, sure vaccine. Just knowing if 65% of the population gets vaccinated, what effect would that have? Just even knowing those things, just modeling all those things. Given all the other incentives, I mean, Pfizer,
Sam Harris (03:12:42):
I don’t know what to think. But you had the CEO of Pfizer on your podcast. Did you leave that conversation feeling like this is a person who is consciously reaping windfall profits on a dangerous vaccine and putting everyone at intolerable risk? Or do you think this person, did you think this person was making a good faith attempt to save lives and had no taint of bad incentives or something?
Lex Fridman (03:13:18):
The thing I sensed and I felt in part, it was a failure on my part, but I sensed that I was talking to a politician. So it’s not thinking of, there was malevolence there or benevolence. There was a- He just had a job. He put on a suit and I was talking to a suit, not a human being. Now, he said that his son was a big fan of the podcast, which is why he wanted to do it. So I thought I would be talking to a human being. And I asked challenging questions, what I thought the internet thinks otherwise. Every single question in that interview was a challenging one. But it wasn’t grilling, which is what people seem to want to do with pharmaceutical companies. There’s a deep distrust of pharmaceutical companies.
Sam Harris (03:14:08):
What’s the alternative? I mean, I totally get that windfall profits at a time of a public health emergency looks bad. It is a bad look, right? But how do we reward and return capital to risk-takers who will spend a billion dollars to design a new drug for a disease that maybe only harms a single digit percentage of the population? It’s like, well, what do we want to encourage? And who do we want to get rich? I mean, so like the person who cures cancer, do we want that person to get rich or not? We want the person who gave us the iPhone to get rich, but we don’t want the person who cures cancer to get rich?
Lex Fridman (03:14:54):
What are we trying to do? I think it’s a very gray area. So what we want is the person who declares that they have a cure for cancer to have authenticity and transparency. I think we’re good now as a population smelling bullshit. And there is something about the Pfizer CEO, for example, just CEOs of pharmaceutical companies in general, just because they’re so lawyered up, so much marketing and PR people, they are, you just smell bullshit. You’re not talking to a real human. It just feels like none of it is transparent to us as a public.
(03:15:31):
So like this whole talking point that Pfizer’s only interested in helping people just doesn’t ring true, even though it very well could be true. It’s the same thing with Bill Gates, who seems to be at scale helping a huge amount of people in the world. And yet there’s something about the way he delivers that message, where people like, he seems suspicious. What’s happening underneath this? There’s certain kinds of communication styles that seem to be more, serve as better catalysts for conspiracy theories. And I’m not sure what that is, because I don’t think there’s an alternative for capitalism in delivering drugs that help people. But also at the same time, there seems to need to be more transparency. And plus like regulation, that actually makes sense, versus it seems like pharmaceutical companies are susceptible to corruption.
Sam Harris (03:16:27):
Yeah, I worry about all that. But I also do think that most of the people going into those fields, and most of the people going into government, they’re doing it for a good, they’re non-psychopaths trying to get good things done and trying to solve hard problems. And they’re not trying to get rich. I mean, many of the people are, it’s like, bad incentives are something, again, I’ve uttered that phrase 30 times on this podcast, but it’s just almost everywhere it explains normal people creating terrible harm, right? It’s not that there are that many bad people. And yes, it makes the truly bad people that much more remarkable and worth paying attention to, but the bad incentives and the power of bad ideas do much more harm. Because I mean, that’s what gets good people running in the wrong direction or doing things that are clearly creating unnecessary suffering.
Lex Fridman (03:17:39):
You’ve had, and I hope still have, a friendship with Elon Musk, especially over the topic of AI. You have a lot of interesting ideas that you both share, concerns that you both share. Well, let me first ask, what do you admire most about Elon?
Sam Harris (03:17:57):
Well, you know, I’ve had a lot of fun with Elon. I like Elon a lot. I mean, Elon, I knew as a friend, I like a lot. And it’s not going to surprise anyone. I mean, he’s done and he’s continuing to do amazing things. And I think he’s, you know, I think many of his aspirations are realized, the world would be a much better place. I think it’s just, it’s amazing to see what he’s built and what he’s attempted to build and what he may yet build.
Lex Fridman (03:18:32):
So with Tesla, with SpaceX, with-
Sam Harris (03:18:34):
Yeah, no, I’m a fan of almost all of that. I mean, there are wrinkles to a lot of that, you know, or some of that.
Lex Fridman (03:18:43):
All humans are full of wrinkles.
Sam Harris (03:18:45):
There’s something very Trumpian about how he’s acting on Twitter. I mean, Twitter, I think Twitter’s, he thinks Twitter’s great. He bought the place because he thinks it’s so great. I think Twitter’s driving him crazy, right? I think he’s needlessly complicating his life and harming his reputation and creating a lot of noise and harming a lot of other people. I mean, so like he, the thing that I objected to with him on Twitter is not that he bought it and made changes to it. I mean, that was not, again, I remain agnostic as to whether or not he can improve the platform. It was how he was personally behaving on Twitter, not just toward me, but toward the world. I think when you forward an article about Nancy Pelosi’s husband being attacked, not as he was by some lunatic, but that it’s just some gay trist gone awry, right? That’s not what it seems. And you link to a website that previously claimed that Hillary Clinton was dead and that a body double was campaigning in her place.
(03:19:50):
That thing was exploding in Trumpistan as a conspiracy theory, right? And it was having its effect. And it matters that he was signal boosting it in front of 130 million people. And so it is with saying that your, you know, your former employee, Yoel Roth, is a pedophile, right? I mean, it’s like, that has real consequences. It appeared to be complete bullshit. And now this guy’s getting inundated with death threats, right, and Elon, all of that’s totally predictable.
(03:20:19):
Right, and so he’s behaving quite recklessly. And there’s a long list of things like that that he’s done on Twitter. It’s not ethical. It’s not good for him. It’s not good for the world. It’s not serious. It’s just, it’s a very adolescent relationship to real problems in our society. And so my problem with how he’s behaved is that he’s purported to touch real issues by turns. Like, okay, do I give the satellites to Ukraine or not? Do I minimize their use of them or not? Is this, should I publicly worry about World War III or not, right? He’s doing this shit on Twitter, right?
(03:21:01):
And at the same moment, he’s doing these other very impulsive, ill-considered things, and he’s not showing any willingness to really clean up the mess he makes. He brings Kanye on, knowing he’s an anti-Semite who’s got mental health problems, and then kicks him off for a swastika, which I probably wouldn’t have kicked him off for a swastika, it’s like, that’s even like, can you really kick people off for swastikas? Is that something that you get banned for, I mean, are you a free speech absolutist if you can’t let a swastika show up? I’m not even sure that’s an enforceable terms of service, right, there are moments to use swastikas that are not conveying hate and not raising the risk of violence. Clip that. Yeah, any, but so much of what he’s doing, given that he’s, again, scale matters. He’s doing this in front of 130 million people. That’s very different than a million people, and that’s very different than 100,000 people, and so when I went off the tracks with Elon, he was doing this about COVID, and again, this was a situation where I tried to privately mitigate a friend’s behavior, and it didn’t work out very well.
Lex Fridman (03:22:14):
Did you try to correct him, sort of highlighting things he might be wrong on? Yeah. Or did you use the Lex Powell love method? I should write like a pamphlet for Sam Harris.
Sam Harris (03:22:25):
Well, no, but it was totally coming from a place of love because I was concerned about his reputation. I was concerned about what he, I mean, there was a twofold concern. I could see what was happening with the tweet. I mean, he had this original tweet that was, I think it was, panic over COVID is dumb, or something like that, right? And this is way, this is in March, this is early March, 2020.
Lex Fridman (03:22:48):
Oh, super early days.
Sam Harris (03:22:49):
Super early, when nobody knew anything, but we knew, we saw what was happening in Italy, right? It was totally kicking off.
Lex Fridman (03:22:56):
God, that was a wild time.
Sam Harris (03:22:58):
That’s when the toilet paper- And wild, it was totally wild, but that became the most influential tweet on Twitter for that week. I mean, it had more engagement than any other tweet, more than any crazy thing Trump was tweeting. I mean, it was, it went off, again, it was just a nuclear bomb of information. And I could see that people were responding to it like, wait a minute, okay, here’s this genius technologist who must have inside information about everything, right? Surely he knows something that is not on the surface about this pandemic. And they’re reading, they were reading into it a lot of information that I knew wasn’t there, right? And at the time, I didn’t even, I didn’t think he had any reason to be suggesting that. I think he was just firing off a tweet, right?
(03:23:47):
So I reached out to him in private, and I mean, because it was a private text conversation, I won’t talk about the details, but I’m just saying, that’s a case, among the many cases of friends who have public platforms and who did something that I thought was dangerous and ill-considered, this was a case where I reached out in private and tried to help, genuinely help, because it was just, I thought it was harmful in every sense, because it was being misinterpreted. And it was like, okay, you can say that panic over anything is dumb, fine, but this was not how this was landing. This was like, non-issue, conspiracy, there’s gonna be no COVID in the US, it’s gonna peter out, it’s just gonna become a cold. I mean, that’s how this was getting received. Whereas at that moment, it was absolutely obvious how big a deal this was gonna be, or that it was gonna, at minimum, going to be a big deal.
Lex Fridman (03:24:45):
I don’t know if it was obvious, but it was obvious there was a significant probability that it could be a big deal. I remember in March, it wasn’t unclear, like, how big, because there’s still stories of it, like it’s probably going to, the big concern, the hospitals might overfill, but it’s gonna die out in like two months or something.
Sam Harris (03:25:02):
Yeah, we didn’t know, but there was no way we weren’t going to have tens of thousands of deaths at a minimum at that point. And it was totally rational to be worried about hundreds of thousands. And when Nicholas Christakis came on my podcast, very early, he predicted quite confidently that we would have about a million people dead in the US, right? And that didn’t seem, it was, I think, appropriately hedged, but I mean, it was still, it was just like, okay, it’s just gonna, you just look at the, we’re just kind of riding this exponential and we’re, and it’s gonna be, it’d be very surprising not to have that order of magnitude and not something much, much less. And so anyway, I mean, again, to close the story on Elon, I could see how this was being received and I tried to get him to walk that back.
(03:26:07):
And then we had a fairly long and detailed exchange on this issue and that, so that intervention didn’t work. And it was not done, you know, I was not an asshole. I was not, I was just concerned, you know, for him, for the world, for, and, you know. And then there are other relationships where I didn’t take the, again, that’s an example where taking the time didn’t work, right, privately. There are other relationships where I thought, okay, this is just gonna be more trouble than it’s worth, and I just ignored it, you know.
(03:26:44):
And there’s a lot of that, and I, again, I’m not comfortable with how this is all netted out because I don’t know if, you know, and I’m not, you know, frankly, I’m not comfortable with how much time in this conversation we’ve spent talking about these specific people. Like, what good is it for me to talk about Elon or Brett or any of these people in public?
Lex Fridman (03:27:06):
I think there’s a lot of good, because those friendships, listen, as a fan, these are the conversations that I loved, love as a fan, and it feels like COVID has robbed the world of these conversations. Because you are exchanging back and forth on Twitter, but that’s not what I mean by conversations, like long-form discussions, like a debate about COVID,
Sam Harris (03:27:31):
like a normal discussion, like a normal debate. But there’s no, Elon and I shouldn’t be debating COVID.
Lex Fridman (03:27:37):
You should be. Here’s the thing, with humility, like basically saying, we don’t really know, like the Rogan method, we’re just a bunch of idiots. Like, one is an engineer, you’re a neuroscientist, but like, it just kind of, okay, here’s the evidence, and be like normal people. That’s what everybody was doing. The whole world was like trying to figure out what the hell, what?
Sam Harris (03:27:56):
Yeah, but the issue was that at that, so at the moment I had this collision with Elon, certain things were not debatable, right? It was just, it was absolutely clear where this was going. It wasn’t clear how far it was gonna go or how quickly we would mitigate it, but it was absolutely clear that it was gonna be an issue, right? The train had come off the tracks in Italy. We knew we weren’t gonna seal our borders, there were already people, you know, there are already cases known to many of us personally in the US at that point.
(03:28:35):
And he was operating by a very different logic that I couldn’t engage with.
Lex Fridman (03:28:41):
Sure, but that logic represents a part of the population, and there’s a lot of interesting topics that have a lot of uncertainty around them, like the effects of climate change, uncertainty around them, like the effectiveness of masks, like-
Sam Harris (03:28:51):
Yeah, but no, but where things broke down was not at the point of, oh, there’s a lot to talk about, a lot to debate, this is all very interesting, and who knows what’s what. It broke down very early at, this is, you know, there’s nothing to talk about here. Like, it like, it’s like either there’s a water bottle on the table or there isn’t, right? Like-
Lex Fridman (03:29:13):
Yeah. But technically, there’s only 1 4th of a water bottle. So what defines a water bottle? Is it the water inside the water bottle, or is it the water bottle? What I’m giving you as an example of, it’s worth a conversation.
Sam Harris (03:29:26):
This is difficult because this is, we had an exchange in private, and I want to- Sure, sure, sure. I want to honor not exposing the details of it, but, you know, the details convinced me that there was not a follow-up conversation on that topic.
Lex Fridman (03:29:44):
On this topic. Yeah. That said, I hope, and I hope to be part of helping that happen, that the friendship is rekindled, because one of the topics I care a lot about, artificial intelligence, you’ve had great public and private conversations about this topic, and-
Sam Harris (03:30:01):
Yeah, and Elon was very formative in my taking that issue seriously. I mean, he and I went to that initial conference in Puerto Rico together, and it was only because he was going, and I found out about it through him, and I just wrote his coattails to it, you know, that I got dropped in that side of the pool to hear about these concerns at that point.
Lex Fridman (03:30:26):
It would be interesting to hear how has your concern evolved with the coming out of Chad GPT and these new large language models that are fine-tuned with reinforcement learning, and seemingly to be able to do some incredible human-like things. There’s two questions. One, how has your concern in terms of AGI and superintelligence evolved, and how impressed are you with Chad GPT as a student of the human mind, and mind in general?
Sam Harris (03:30:57):
Well, my concern about AGI is unchanged. And so I did a, I’ve spoken about it a bunch on my podcast, but I did a TED Talk in 2016, which was the kind of summary of what that conference and various conversations I had after that did to my brain on this topic.
Lex Fridman (03:31:20):
Basically, that once superintelligence is achieved, there’s a takeoff, it becomes exponentially smarter, and in a matter of time, there’s just, we’re ants, and they’re gods.
Sam Harris (03:31:33):
Well, yeah, and unless we find some way of permanently tethering a superintelligent self-improving AI to our value system, and I don’t believe anyone has figured out how to do that, or whether that’s even possible in principle. I mean, I know people like Stuart Russell, who I just had on my podcast, are- Oh, really?
Lex Fridman (03:31:58):
Have you released it yet? I haven’t released it yet, yeah. Oh, great, that’s great.
Sam Harris (03:32:02):
He’s been on previous podcasts, but we just recorded this week.
Lex Fridman (03:32:04):
Because you haven’t done an AI podcast in a while.
Sam Harris (03:32:06):
So that’s great, that’s great. He’s a good person to talk about alignment with. Yeah, so Stuart, I mean, Stuart has been probably more than anyone my guru on this topic. I mean, like, just reading his book and doing, I think I’ve done two podcasts with him at this point.
Lex Fridman (03:32:21):
I think it’s called The Control Problem or something.
Sam Harris (03:32:23):
His book is human-compatible. Human-compatible. Yeah, he talks about the control problem. And yeah, so I just think the idea that we can define a value function in advance that permanently tethers a self-improving super-intelligent AI to our values as we continue to discover them, refine them, extrapolate them in an open-ended way.
(03:32:54):
I think that’s a tall order, and I think there are many more ways, there must be many more ways of designing super-intelligence that is not aligned in that way, and is not ever approximating our values in that way. So I mean, Stuart’s idea, to put it in a very simple way, is that he thinks you don’t want to specify the value function up front. You don’t want to imagine you could ever write the code in such a way as to admit of no loophole. You want to make the AI uncertain as to what human values are, and perpetually uncertain, and always trying to ameliorate that uncertainty by hewing more and more closely to what our professed values are. So it’s always interested in us saying, oh no, no, that’s not what we want, that’s not what we intend, stop doing that. No matter how smart it gets, all it wants to do is more perfectly approximate human values. I think there are a lot of problems with that at a high level. I’m not a computer scientist, so I’m sure there are many problems at a low level that I don’t understand.
Lex Fridman (03:33:59):
Like how to force a human into the loop,
Sam Harris (03:34:01):
always, no matter what. There’s that, and like what humans get a vote, and just what do humans value, and what is the difference between what we say we value and our revealed preferences, which, I mean, if you were a super intelligent AI that could look at humanity now, I think you could be forgiven for concluding that what we value is driving ourselves crazy with Twitter and living perpetually on the brink of nuclear war and just watching hot girls in yoga pants on TikTok again and again and again. It’s like what- And you’re saying that is not what we- This is all revealed preference, and it’s what is an AI to make of that, and what should it optimize? Like, so part of, this is also Stuart’s observation that one of the insidious things about like the YouTube algorithm is it’s not that it just caters to our preferences. It actually begins to change us in ways so as to make us more predictable. It’s like it finds ways to make us a better reporter of our preferences and to trim our preferences down so that it can further train to that signal. So the main concern is that most of the people in the field seem not to be taking intelligence seriously. Like as they design more and more intelligent machines, and as they profess to want to design true AGI, they’re not, again, they’re not spending the time that Stuart is spending trying to figure out how to do this safely, above all.
(03:35:48):
They’re just assuming that these problems are going to solve themselves as we make that final stride into the end zone. Or they’re saying very, you know, Pollyanna-ish things like, you know, an AI would never form a motive to harm humans. Like why would it ever form a motive to be malicious toward humanity, right? Unless we put that motive in there, right? And that’s not the concern. The concern is that in the presence of vast disparities in competence, and certainly in a condition where the machines are improving themselves, they’re improving their own code, they could be developing goal, instrumental goals that are antithetical to our well-being without any intent to harm us, right? It’s analogous to what we do to every other species on earth.
(03:36:44):
I mean, you and I don’t consciously form the intention to harm insects on a daily basis, but there are many things we could intend to do that would, in fact, harm insects because, you know, you decide to repave your driveway or whatever you’re doing, like you’re just not taking the interest of insects into account because they’re so far beneath you in terms of your cognitive horizons. And so the real challenge here is that if you believe that intelligence, you know, scales up on a continuum toward heights that we can only dimly imagine, and I think there’s every reason to believe that, and there’s no reason to believe that we’re near the summit of intelligence, and you can, you know, define, maybe there’s some forms of intelligence for which this is not true, but for many relevant forms, you know, like the top 100 things we care about cognitively, I think there’s every reason to believe that many of those things, most of those things are a lot like chess or go, where once the machines get better than we are, they’re gonna stay better than we are, although they’re, I don’t know if you caught the recent thing with Go, where this guy actually came out of Stuart’s lab. Yeah.
Lex Fridman (03:37:60):
Yeah. Yeah. One time a human beat a machine.
Sam Harris (03:38:04):
Yeah, they found a hack for that, but anyway, ultimately, there’s gonna be no looking back, and then the question is, what do we do in relationship to these systems that are more competent than we are in every relevant respect? Because it will be a relationship. It’s not like, the people who think we’re just gonna figure this all out, you know, without thinking about it in advance, it’s just gonna, the solutions are just gonna find themselves, seem not to be taking the prospect of really creating autonomous superintelligence seriously. Like, what does that mean? It’s every bit as independent and ungovernable, ultimately, as us having created, I mean, just imagine if we created a race of people that were 10 times smarter than all of us. Like, how would we live with those people? They’re 10 times smarter than us, right? Like, they begin to talk about things we don’t understand. They begin to want things we don’t understand. They begin to view us as obstacles to them, so they’re solving those problems. We’re gratifying those desires. We become the chickens or the monkeys in their presence, and I think that it’s, but for some amazing solution of the sort that Stuart is imagining, that we could somehow anchor their reward function permanently, no matter how intelligent scales, I think it’s really worth worrying about this. I do buy the sci-fi notion that this is an existential risk if we don’t do it well.
Lex Fridman (03:39:50):
I worry that we don’t notice it. I’m deeply impressed with Chad GPT, and I’m worried that it will become superintelligent. These language models will become superintelligent because they’re basically trained in the collective intelligence of the human species, and then it’ll start controlling our behavior if they’re integrated into our algorithms, the recommender systems, and then we just won’t notice that there’s a superintelligent system that’s controlling our behavior.
Sam Harris (03:40:21):
Well, I think that’s true even before, far before superintelligence, even before general intelligence. I mean, I think just the narrow intelligence of these algorithms and of what, something like Chad GPT can do, I mean, it’s just far short of it developing its own goals and that are at cross-purposes with ours. Just the unintended consequences of using it in the ways we’re going to be incentivized to use it and the money to be made from scaling this thing and what it does to our information space and our sense of just being able to get to ground truth of on any facts, it’s, yeah, it’s super scary, and it was, it’s.
Lex Fridman (03:41:21):
Do you think it’s a giant leap in terms of the development towards AGI, Chad GPT, or we still, is this just an impressive little toolbox? So, like, when do you think the singularity’s coming?
Sam Harris (03:41:36):
Or is it T, it doesn’t matter if it’s eventually? I have no intuitions on that front, apart from the fact that if we continue to make progress, it will come. Right, so it’s just, you just have to assume we continue to make progress. There’s only two assumptions. You have to assume substrate independence. So there’s no reason why this can’t be done in silico. It’s just, we can build arbitrarily intelligent machines. There’s nothing magical about having this done in the wetware of our own brains. I think that is true, and I think that’s scientifically parsimonious to think that that’s true.
(03:42:12):
And then you just have to assume we’re going to keep making progress. It doesn’t have to be any special rate of progress. It doesn’t have to be Moore’s law. It can just be, we just keep going. At a certain point, we’re going to be in relationship to minds, leaving consciousness aside. I don’t have any reason to believe that they’ll necessarily be conscious by virtue of being super intelligent, and that’s its own interesting ethical question.
(03:42:39):
But leaving conscience aside, they’re going to be more competent than we are. And then that’s like the aliens have landed. That’s literally, that’s an encounter with, again, leaving aside the possibility that something like Stuart’s path is actually available to us. But it is hard to picture if what we mean by intelligence, all things considered, and it’s truly general, if that scales and begins to build upon itself, how you maintain that perfect, slavish devotion until the end of time- In those systems. The tether to humans.
Lex Fridman (03:43:34):
Yeah. I think my gut says that that tether is not, there’s a lot of ways to do it. So it’s not this increasingly impossible problem.
Sam Harris (03:43:45):
Right, so I have no, as you know, I’m not a computer scientist, so I have no intuitions about just algorithmically how you would approach that and what’s possible.
Lex Fridman (03:43:55):
My main intuition is maybe deeply flawed, but the main intuition is based on the fact that most of the learning is currently happening on human knowledge. So even Chad GPT is just trained on human data. I don’t see where the takeoff happens where you completely go above human wisdom. The current impressive aspect of Chad GPT is that’s using collective intelligence of all of us.
Sam Harris (03:44:23):
From what I glean, again, from people who know much more about this than I do, I think we have reason to be skeptical that these techniques of deep learning are actually going to be sufficient to push us into AGI. Right, so it’s just, they’re not generalizing in the way they need to. They’re certainly not learning like human children, and so there’s brittle and strange ways. It’s not to say that the human path is the only path, you know, and maybe we might learn better lessons by ignoring the way brains work, but we know that they don’t generalize and use abstraction the way we do. And so, they have strange holes in their competence.
Lex Fridman (03:45:15):
But the size of the holes is shrinking every time, and that’s, so the intuition starts to slowly fall apart. You know, the intuition is like, surely it can’t be this simple to achieve superintelligence. Yeah, yeah. But it’s becoming simpler and simpler. So I don’t know, I don’t, the progress is quite incredible. I’ve been extremely impressed with Chad GPT, and the new models, and there’s a lot of financial incentive to make progress in this regard. So it’s, we’re going to be living through some very interesting times.
(03:45:48):
In raising a question that I’m going to be talking to you, a lot of people brought up this topic, probably because Eric Weinstein talked to Joe Rogan recently, and said that he and you were contacted by folks about UFOs. Can you clarify the nature of this contact?
Sam Harris (03:46:06):
Can you, that you were contacted by? I’ve got very little to say on this. I mean, he has much more to say. I think he went down this rabbit hole further than I did, which wouldn’t surprise anyone. He’s got much more of a taste for this sort of thing than I do. But I think we were contacted by the same person. It wasn’t clear to me who this person was, or how this person got my cell phone number. They didn’t seem, it didn’t seem like we were getting punked. I mean, the person seemed credible to me.
Lex Fridman (03:46:38):
And they were talking to you about the release of different videos on UFOs.
Sam Harris (03:46:42):
Yeah, and this is when there was a flurry of activity around this. So there was like, there was a big New Yorker article on UFOs, and there was rumors of congressional hearings, rumors of congressional hearings, I think, come in. And there were the videos that were being debunked or not. And so this person contacted both of us, I think, around the same time. And I think he might’ve contacted Rogan or other, Eric is just the only person I’ve spoken to about it, I think, who I know was contacted.
(03:47:17):
And what happened is the person kept writing a check that he didn’t cash. Like he kept saying, okay, next week I’m gonna, I understand this is sounding spooky, and you have no reason to really trust me, but next week I’m gonna put you on a Zoom call with people who you will recognize, and they’re gonna be former heads of the CIA, and people who just, you’re gonna, within five seconds of being on the Zoom call, you’ll know this is not a hoax. And I said, great, just let me know, just send me the Zoom link, right? And I went, that happened maybe three times. There was just one phone conversation, and then it was just texts, just a bunch of texts. And I think Eric spent more time with this person, and I’m not, I haven’t spoken to him about it. I know he spoke about it publicly, but.
(03:48:14):
So I, you know, it’s not that my bullshit detector ever really went off in a big way, it’s just the thing never happened, and so I lost interest.
Lex Fridman (03:48:22):
So you made a comment, which is interesting, that you ran the, which I really appreciate, that you ran the thought experiment of saying, okay, maybe we do have alien spacecraft, or just the thought experiment the aliens did visit. Yeah. And then this very kind of nihilistic, sad thought that it wouldn’t matter, it wouldn’t affect your life. Can you explain that?
Sam Harris (03:48:47):
Well, no, I was, I think many people noticed this. I mean, this was a sign of how crazy the news cycle was at that point, right? It’s like we had COVID, and we had Trump, and I forget when the UFO thing was really kicking off, but it just seemed like no one had the bandwidth to even be interested in this. It’s like, I was amazed to notice in myself that I wasn’t more interested in figuring out what was going on. It’s like, and I considered, okay, wait a minute. This is, if this is true, this is the biggest story in anyone’s lifetime. I mean, contact with alien intelligence is by definition the biggest story in anyone’s lifetime in human history. Why isn’t this just totally captivating? And not only was it not totally captivating, it would just barely rise into the level of my being able to pay attention to it. And I view that, I mean, one, as a, to some degree, an understandable defense mechanism against the bogus claims that have been made about this kind of thing in the past.
(03:50:05):
You know, the general sense is probably bullshit, or it probably has some explanation that is purely terrestrial and not surprising. And there is somebody who, what’s his name? Mick West, I forget, is it a YouTuber?
Lex Fridman (03:50:18):
Yeah, Mick West, yeah. He debunks stuff.
Sam Harris (03:50:21):
Yeah, he, I mean, you know, I have since seen some of those videos. I mean, now this is going back still at least a year, but some of those videos seem like fairly credible debunkings of some of the optical evidence. And I’m surprised we haven’t seen more of that. Like there was a fairly credulous 60 minutes piece that came out around that time, looking at some of that video, and it was the very video that he was debunking on YouTube, and his video only had like 50,000 views on it or whatever. But again, it seemed like a fairly credible debunking. I haven’t seen debunkings of his debunkings, but.
Lex Fridman (03:50:59):
I think there is, but he’s basically saying that there is possible explanations for it. And usually in these kinds of contexts, if there’s a possible explanation, even if it seems unlikely, it’s going to be more likely than an alien civilization
Sam Harris (03:51:14):
in visiting us. Yeah, it’s the extraordinary claims require extraordinary evidence principle, which I think is generally true.
Lex Fridman (03:51:21):
Well, with aliens, I think generally, I think there should be some humility about what they would look like when they show up. But I tend to think they’re already here.
Sam Harris (03:51:31):
The amazing thing about this AI conversation, though, is that we’re talking about a circumstance where we would be designing the aliens, and there’s every reason to believe that eventually this is gonna happen. Like I said, I’m not at all skeptical about the coming reality of the aliens, that we’re gonna build them.
Lex Fridman (03:51:50):
Now, here’s the thing. Does this apply to when superintelligence shows up? Will this be trending on Twitter for a day, and then we’ll go on to complain about something Sam Harris once again said in his podcast the next day? You tend to trend on Twitter, even though you’re not on Twitter, which is great.
Sam Harris (03:52:09):
Yeah, I haven’t noticed. I mean, I did notice when I was on, but… I’m…
Lex Fridman (03:52:16):
Did you have this concern about AGI, basically, the same kind of thing, that we would just look the other way? Is there something about this time where even like World War III, which has been throwing around very casually, concerningly so, even that, the news cycle wipes that away?
Sam Harris (03:52:35):
Yeah. Well, I think we have this general problem that we can’t make certain information, even unequivocally certain information, emotionally salient. Like we respond quite readily to certain things. I mean, as we talked about, we respond to the little girl who fell down a well. I mean, that gets 100% of our emotional resources.
(03:53:10):
But the abstract probability of nuclear war, right, even a high probability, even an intolerable probability, even if we put it at 30%, right? You know, it’s just like that’s a Russian roulette with a gun with three chambers, and it’s aimed at the heads, not only your head, but your kid’s head and everyone’s kid’s head, and it’s just 24 hours a day. And I mean, I think people who, this pre-Ukraine, I think the people who have made it their business to professionally to think about the risk of nuclear war and to mitigate it, people like Graham Allison or William Perry.
(03:53:56):
I mean, I think they were putting like the ongoing risk, I mean, just the risk that we’re gonna have a proper nuclear war at some point in the next generation, people were putting it at something like 50%, right? That we’re living with this sort of Damocles over our heads. Now, you might wonder whether anyone can have reliable intuitions about the probability of that kind of thing, but the status quo is truly alarming. I mean, we’ve got ICBMs on, I mean, leave aside smaller exchanges and tactical nukes and how we could have a world war based on incremental changes.
(03:54:44):
We’ve got the biggest bombs aimed at the biggest cities in both directions and it’s old technology, right? And it’s vulnerable to some lunatic deciding to launch or misreading bad data. And we know we’ve been saved from nuclear war, I think at least twice by Soviet submarine commanders deciding I’m not gonna pass this up the chain of command, right? It’s like, this is almost certainly an error and it turns out it was an error. And we need people to, I mean, in that particular case, like he saw, I think it was five, what seemed like five missiles launched from the US to Russia. And he reasoned if America was gonna engage in a first strike, they’d launch more than five missiles, right? So this has to be fictional. And then he waited long enough to decide that it was fictional. But the probability of a nuclear war happening by mistake or some other species of inadvertence, you know, misunderstanding, technical malfunction, that’s intolerable. Forget about the intentional use of it by people who are driven crazy by some ideology.
Lex Fridman (03:56:14):
And more and more technologies are enabled to the kind of scale of destruction.
Sam Harris (03:56:18):
And misinformation plays into this picture in a way that is especially scary. I mean, once you can get a deep fake of, you know, any current president of the United States claiming to have launched a first strike, you know, and just, you know, send that everywhere.
Lex Fridman (03:56:38):
But that could change the nature of truth. And then we, that might change the engine we have for skepticism, sharpen it.
Sam Harris (03:56:48):
The more you have deep fakes. Yeah, and we might have AI and digital watermarks that help us, maybe we’ll not trust any information that hasn’t come through specific channels, right? I mean, so in my world, it’s like, I no longer feel the need to respond to anything other than what I put out in my channels of information. It’s like, there’s so many people who have clipped stuff of me that shows the opposite of what I was actually saying in context. I mean, the people have like re-edited my podcast audio to make it seem like I said the opposite of what I was saying. It’s like, unless I put it out, you know, you can’t be sure that I actually said it, you know? I mean, it’s just, but I don’t know what it’s like to live like that for all forms of information. And I mean, strangely, I think it may require a greater siloing of information in the end. You know, it’s like, we’re living through this sort of Wild West period where everyone’s got a newsletter and everyone’s got a blog and everyone’s got an opinion, but once you can fake everything.
Lex Fridman (03:58:04):
There might be a greater value for expertise for experts, but a more rigorous system for identifying who the experts are.
Sam Harris (03:58:11):
Yeah, or just knowing that it’s gonna be an arms race to authenticate information. So it’s like, if you can never trust a photograph unless it has been vetted by Getty Images, because only Getty Images has the resources to authenticate the provenance of that photograph and attest that it hasn’t been meddled with by AI. And again, I don’t even know if that’s technically possible. I mean, maybe whatever the tools available for this will be, you know, commodified and the cost will be driven to zero so quickly that everyone will be able to do it. You know, it could be like encryption, but.
Lex Fridman (03:58:52):
And it would be proven and tested most effectively first, of course, as always in porn. Yeah, right. Which is where most of human innovation technology happens first. Well, I have to ask because Ron Howard, the director, asked this on Twitter. Since we’re talking about the threat of nuclear war and otherwise, he asked, I’d be interested in both your expectations for human society if, when we move beyond Mars.
(03:59:19):
Will those societies be industrial-based? How will it be governed? How will criminal infractions be dealt with when you read or watch sci-fi? What comes closest to sounding logical? Do you think about our society beyond Earth? If we colonize Mars, if we colonize space?
Sam Harris (03:59:35):
Yeah, well, I think I have a pretty humbling picture of that. So, because we’re still gonna be the apes that we are. So, when you imagine colonizing Mars, you have to imagine a first fist fight on Mars. Yeah. You have to imagine a first murder on Mars. Also, infidelity. Yeah. Somebody. The extramarital affairs on Mars, right? So, it’s gonna get really homely and boring really fast, I think. It’s like only the spacesuits or the other exigencies of just living in that atmosphere or lack thereof will limit how badly we can behave on Mars.
Lex Fridman (04:00:16):
But do you think most of the interaction will be still in meat space versus digital? Do you think there’ll be, do you think we’re like living through a transformation of a kind where we’re going to be doing more and more interaction in digital space? Like everything we’ve been complaining about Twitter, is it possible that Twitter’s just the early days of a broken system that’s actually giving birth to a better working system that’s ultimately digital?
Sam Harris (04:00:44):
I think we’re gonna experience a pendulum swing back into the real world. I mean, I think many of us are experiencing that now anyway. I mean, just wanting to have face-to-face encounters and spend less time on our phones and less time online. I think maybe everyone isn’t going in that direction, but I do notice it myself. And I notice, I mean, once I got off Twitter, then I noticed the people who were never on Twitter, right? And the people who were never, basically, I mean, I know I have a lot of friends who are never on Twitter. Yeah. And they actually never understood what I was doing on Twitter. It’s like, they just like, it wasn’t that they were seeing it and then reacting to it. They just didn’t know.
(04:01:33):
It’s like, it’s like being on, it’s like I’m not on Reddit either, but I don’t spend any time thinking about not being on Reddit, right? It’s like, I’m just not on Reddit.
Lex Fridman (04:01:40):
So you think the pursuit of human happiness is better achieved, more effectively achieved outside of Twitter world?
Sam Harris (04:01:49):
Well, I think all we have is our attention in the end. And we just have to notice what these various tools are doing to it. And it’s just, it became very clear to me that it was an unrewarding use of my attention. Now, it’s not to say there isn’t some digital platform that’s conceivable that would be useful and rewarding, but yeah, I mean, we just have, our life is doled out to us in moments and we have, and we’re continually solving this riddle of what is going to suffice to make this moment engaging and meaningful and aligned with who I want to be now and how I want the future to look, right? We have this tension between being in the present and becoming in the future.
(04:02:47):
And it’s a seeming paradox. Again, it’s not really a paradox, but it can seem like, I do think the ground truth for personal wellbeing is to find a mode of being where you can pay attention to the present moment. And this is meditation by another name. You can pay attention to the present moment with sufficient gravity that you recognize that just consciousness itself in the present moment, no matter what’s happening is already a circumstance of freedom and contentment and tranquility. Like you can be happy now before anything happens, before this next desire gets gratified, before this next problem gets solved. There’s this kind of ground truth that you’re free, that consciousness is free and open and unencumbered by really any problem until you get lost in thought about all the problems that may yet be real for you.
Lex Fridman (04:03:50):
So the ability to catch and observe consciousness, that in itself is a source of happiness.
Sam Harris (04:03:56):
Yeah, without being lost in thought. And so this happens haphazardly for people who don’t meditate because they find something in their life that’s so captivating, it’s so pleasurable, it’s so thrilling. It can even be scary, but it can be, even being scared is captivating, it gets their attention, right? Whatever it is. Sebastian Junger wrote a great book about people’s experience in war here. Strangely, it can be the best experience anyone’s ever had because everything, it’s like only the moment matters, right? Like the bullet is whizzing by your head. You’re not thinking about your 401k or that thing that you didn’t say last week to the person you shouldn’t have been talking about. You’re not thinking about Twitter.
(04:04:45):
It’s like you’re just fully immersed in the present moment. Meditation is the only way, I mean, that word can mean many things to many people, but what I mean by meditation is simply the discovery that there is a way to engage the present moment directly, regardless of what’s happening. You don’t need to be in a war. You don’t need to be having sex. You don’t need to be on drugs. You don’t need to be surfing. Nothing, it doesn’t have to be a peak experience. It can be completely ordinary, but you can recognize that in some basic sense, there’s only this and everything else is something you’re thinking. You’re thinking about the past. You’re thinking about the future and thoughts themselves have no substance, right? It’s fundamentally mysterious that any thought ever really commandeers your sense of who you are and makes you anxious or afraid or angry or whatever it is. And the more you discover that, the half-life of all these negative emotions that blow all of us around get much, much shorter, right? And you can literally just, the anger that would have kept you angry for hours or days lasts four seconds because you just, the moment it arises, you recognize it and you can get off it. You can decide, at minimum, you can decide whether it’s useful to stay angry at that moment. And obviously, it usually isn’t. And the illusion of free will
Lex Fridman (04:06:13):
is one of those thoughts.
Sam Harris (04:06:15):
Yeah, it’s all just happening, right? Like even the mindful and meditative response to this is just happening. It’s just like even the moments where you recognize or not recognize is just happening. It’s not that, this does open up a degree of freedom for a person, but it’s not a freedom that gives any motivation to the notion of free will. It’s just a new way of being in the world.
Lex Fridman (04:06:38):
Is there a difference between intellectually knowing free will is an illusion and really experiencing it? What’s the longest you’ve been able to experience, the escape, the illusion of free will?
Sam Harris (04:06:53):
Well, it’s always obvious to me when I pay attention. I mean, whenever I’m mindful, the term of jargon in the Buddhist and increasingly outside the Buddhist context is mindfulness, right? But there are sort of different levels of mindfulness and there’s different degrees of insight into this. But yes, what I’m calling evidence of lack of free will and lack of the self, I’ve got two sides of the same coin. There’s a sense of being a subject in the middle of experience to whom all experience refers, the sense of I, the sense of me.
(04:07:34):
And that’s almost everybody’s starting point when they start to meditate. And that’s almost always the place people live most of their lives from. I do think that gets interrupted in ways they get unrecognized. I think people are constantly losing the sense of I, they’re losing the sense of subject-object distance, but they’re not recognizing it. And meditation is the mode in which you can recognize, you can recognize, you can both consciously precipitate it, you can look for the self and fail to find it and then recognize its absence.
(04:08:07):
And that’s just the flip side of the coin of free will. I mean, the feeling of having free will is what it feels like to feel like a self who’s thinking his thoughts and doing his actions and intending his intentions. And the man in the middle of the boat who’s rowing, that’s the false starting point. When you find that there’s no one in the middle of the boat, right? Or in fact, there’s no boat, there’s just the river, there’s just the flow of experience and there’s no center to it. And there’s no place from which you would control it. Again, even when you’re doing things, this does not negate the difference between voluntary and involuntary behavior.
(04:08:50):
It’s like, I can voluntarily reach for this, but when I’m paying attention, I’m aware that everything is just happening. Like just the intention to move is just arising, right? And I’m in no position to know why it didn’t arise a moment before or a moment later or a moment or 50% stronger or weaker or so as to be ineffective or to be doubly effective where I lurched for it versus I move slow. I mean, I’m not, I can never run the counterfactuals. I can never, all of this opens the door to an even more disconcerting picture along the same lines, which is subsumes this conversation about free will. And it’s the question of whether anything is ever possible. Like what if, this is a question I haven’t thought a lot of about it, but it’s been a few years, I’ve been kicking this question around.
(04:09:55):
So I mean, what if only the actual is possible? What if there was, what if, so we live with this feeling of possibility. We live with the sense that, let me take, so I have two daughters. I could have had a third child, right? So what does it mean to say that I could have had a third child? Or it’s a, you don’t have kids, I don’t think.
Lex Fridman (04:10:21):
Not that I know of. So the possibility might be there.
Sam Harris (04:10:24):
So what do we mean when we say you could have had a child or you might have a child in the future? Like what is the space in reality? What’s the relationship between possibility and actuality and reality? Is there a reality in which non-actual things are nonetheless real? And so we have other categories of like non-concrete things. We have things that don’t have spatial, temporal dimension, but they’re nonetheless, they nonetheless exist. So like, you know, the integers, right? So numbers.
(04:11:07):
So there’s a reality, there’s an abstract reality to numbers. And this is, it’s philosophically interesting to think about these things. So they’re not like, in some sense, they’re real and they’re not merely invented by us. They’re discovered because they have structure that we can’t impose upon them, right? It’s not like, they’re not fictional characters like, you know, I mean, like Hamlet and Superman also exist in some sense, but they exist at the level of our own fiction and abstraction. But it’s like, they’re true and false statements you can make about Hamlet. They’re true and false statements you can make about Superman, because our fiction, the fictional worlds we’ve created have a certain kind of structure. But again, this is all abstract. It’s like, it’s all abstractable from any of its concrete instantiations. It’s not just in the comic books and just in the movies. It’s in our ongoing ideas about these characters. But natural numbers or the integers don’t function quite that way. I mean, they’re similar, but they also have a structure that’s purely a matter of discovery. It’s not, you can’t just make up whether numbers are prime.
(04:12:19):
You know, if you give me two integers of a certain size, let’s say you mentioned two enormous integers. If I were to say, okay, well, between those two integers, they’re exactly 11 prime numbers, right? That’s a very specific claim about which I can be right or wrong, and whether or not anyone knows I’m right or wrong. It’s like, that’s just, there’s a domain of facts there, but these are abstract, it’s an abstract reality that relates in some way that’s philosophically interesting, you know, metaphysically interesting to what we call real reality. You know, the spatial temporal order, the physics of things.
(04:12:57):
Possibility, at least in my view, occupies a different space and this is something, again, my thoughts on this are pretty inchoate, and I think I need to talk to a philosopher of physics and or a physicist about how this may interact with things like the many worlds interpretation.
Lex Fridman (04:13:15):
Yeah, that’s an interesting, right, exactly. So I wonder if discoveries in physics, like further proof or more concrete proof that many worlds interpretation of quantum mechanics has some validity, if that completely starts to change things.
Sam Harris (04:13:31):
But even, that’s just more actuality. So if I took that seriously, that’s a case of, and the truth is that happens even if the many worlds interpretation isn’t true, but we just imagine we have a physically infinite universe, the implication of infinity is such that things will begin to repeat themselves, you know, the farther you go in space, right? You know, if you just head out in one direction, eventually you’re gonna meet two people just like us having a conversation just like this, and you’re gonna meet them an infinite number of times in every, you know, infinite variety of permutations slightly different from this conversation, right? So, I mean, infinity is just so big that our intuitions of probability completely break down. But what I’m suggesting is, maybe probability isn’t a thing, right? Maybe there’s only actuality. If there’s, maybe there’s only what happens, and at every point along the way, our notion of what could have happened or what might’ve happened is just that, it’s just a thought about what could have happened or might have happened.
Lex Fridman (04:14:39):
So it’s a fundamentally different thing. If you can imagine a thing that doesn’t make it real. So they, cause that’s where that possibility exists, it’s in your imagination, right?
Sam Harris (04:14:49):
Yeah, and possibility itself is a kind of spooky idea because it too has a sort of structure, right? So like, if I’m gonna say, you know, you could have had a daughter, right, last year. So we’re saying that’s possible, but not actual, right? That is a claim, there are things that are true and not true about that daughter, right? Like it has a kind of structure, it’s like.
Lex Fridman (04:15:28):
I feel like there’s a lot of fog around that possibility. It feels like almost like a useful narrative.
Sam Harris (04:15:34):
But what does it mean? So like, what does it mean if we say, you know, I just did that, but it’s conceivable that I wouldn’t have done that, right? Like it’s possible that I just threw this cap, but I might not have done that.
Lex Fridman (04:15:49):
So you’re taking it very temporally close to the original, like what would appear as a decision.
Sam Harris (04:15:55):
Whenever we’re saying something’s possible, but not actual, right? Like this thing just happened, but it’s possible that it wouldn’t have happened or that it would have happened differently. In what does that possibility consist? Like where is that? For that to be real, for the possibility to be real, what claim are we making about the universe?
Lex Fridman (04:16:21):
Well, isn’t that an extension of the idea that free will is an illusion, that all we have is actuality, that the possibility is an illusion?
Sam Harris (04:16:28):
Right, yeah, I’m just extending it beyond human action. This goes to the physics of things, this is just everything. Like we’re always telling ourselves a story that includes possibility.
Lex Fridman (04:16:41):
Possibility is really compelling for some reason.
Sam Harris (04:16:45):
Well, yeah, well, because it’s, I mean, so this, yeah, I mean, this could sound just academic, but every backward-looking regret or disappointment and every forward-looking worry is completely dependent on this notion of possibility. Like every regret is based on the sense that something else, I could have done something else, something else could have happened. Every disposition to worry about the future is based on the feeling that there’s this range of possibilities. It could go either way. And, you know, I mean, whether or not there’s such a thing as possibility, you know, I’m convinced that worry is almost never psychologically appropriate because the reality is that in any given moment, either you can do something to solve the problem you’re worried about or not. So if you can do something, just do it. You know, and if you can’t, your worrying is just causing you to suffer twice over, right, you’re gonna, you know, you’re gonna get the medical procedure next week anyway. How much time between now and next week do you wanna spend worrying about it, right? It’s gonna, the worry doesn’t accomplish anything.
Lex Fridman (04:17:55):
How much do physicists think about possibility?
Sam Harris (04:17:58):
Well, they think about it in terms of probability more often, but probability just describes, and again, this is a place where I might be out of my depth and need to talk to somebody to debunk this, but the- Do therapy with a physicist. Yeah, but probably it seems just describes a pattern of actuality that we’ve observed, right? I mean, we have, there are certain things we observe and those are the actual things that have happened. And we have this additional story about probability. I mean, we have the frequency with which things happen, have happened in the past.
(04:18:37):
You know, I can flip a fair coin and know, I know in the abstract that I have a belief that in the limit that those flips, those tosses should converge on 50% heads and 50% tails. I know I have a story as to why it’s not gonna be exactly 50% within any arbitrary timeframe. But in reality, all we ever have are the observed tosses, right? And then we have an additional story that, oh, it came up heads, but it could have come up tails. So why do we think that, about that last toss?
(04:19:13):
And what are we claiming is true about the physics of things if we say it could have been otherwise?
Lex Fridman (04:19:25):
I think we’re claiming that probability is true. That it just, it allows us to have a nice model about the world, gives us hope about the world.
Sam Harris (04:19:35):
Yeah. It seems that possibility has to be somewhere to be effective. It’s a little bit like what’s happening with the laws of, there’s something metaphysically interesting about the laws of nature too, because the laws of nature, so the laws of nature impose their work on the world, right? We see their evidence. But they’re not reducible to any specific set of instances. Right? So there’s some structure there, but the structure isn’t just a matter of the actual things. We have the actual billiard balls that are banging into each other.
(04:20:12):
All of that actuality can be explained by what actual things are actually doing. But then we have this notion that in addition to that, we have the laws of nature that are making, they’re explaining this act, but how are the laws of nature an additional thing in addition to just the actual things that are actually affect causally? And if they are an additional thing, how are they effective? If they’re not among the actual things that are just actually banging around?
Lex Fridman (04:20:39):
And so, to some degree- For that, possibility has to be hiding somewhere for the laws of nature to be- To be possible.
Sam Harris (04:20:46):
For anything to be possible, it has to be, it has to have-
Lex Fridman (04:20:48):
It’s a closet somewhere, I’m sure,
Sam Harris (04:20:51):
where all the possibility goes. It has to be attached to something.
Lex Fridman (04:20:55):
You don’t think Many Worlds is that.
Sam Harris (04:20:58):
Because Many Worlds still exists. Well, because we’re in this strand of that multiverse. Yeah. Right? So, still you have just a local instance of what is actual. Yeah. And then if it proliferates elsewhere where you can’t be affected by it,
Lex Fridman (04:21:13):
there’s more actuality. You can’t really connect with the other.
Sam Harris (04:21:16):
Yeah. Yeah. So, Many Worlds is just a statement of basically everything that can happen, happens somewhere. Yeah. And that’s, I mean, maybe that’s not an entirely kosher formulation of it, but it seems pretty close. So, but there’s whatever happens. Right? In fact, there’s, you know, relativistically, there’s an, you know, Einstein’s original notion of a block universe seems to suggest this.
(04:21:45):
And it’s been a while since I’ve been in a conversation with a physicist where I’ve gotten a chance to ask about the standing of this concept in physics currently. I don’t hear it discussed much, but the idea of a block universe is that, you know, space-time exists as a totality in our sense that we are traveling through space-time where there’s a real difference between the past and the future, that that’s an illusion of just our, you know, the weird slice we’re taking of this larger object. But on some level, it’s like, you know, you’re reading a novel, the last page of the novel exists just as much as the first page when you’re in the middle of it. And they’re just, you know, if that’s, if we’re living in anything like that, then there’s no such thing as possibility. I would, it would seem there’s just what is actual. So as a matter of our experience moment to moment, I think it’s totally compatible with that being true, that there is only what is actual. And that sounds to the naive ear, that sounds like it would be depressing and disempowering and confining, but as anything, but it’s actually, it’s a circumstance of pure discovery. Like you have no idea what’s gonna happen next, right? You don’t know who you’re gonna be tomorrow. You’re only by tendency seeming to resemble yourself from yesterday. And there’s way more freedom in all of that than it seems true to many people. And yet the basic insight is that you’re not, you’re not in, the real freedom is the recognition that you’re not in control of anything. Everything is just happening, including your thoughts and intentions and moods.
Lex Fridman (04:23:37):
So life is a process of continuous discovery.
Sam Harris (04:23:40):
You’re part of the universe. You are just this, I mean, it’s the miracle that the universe is illuminated to itself, as itself, where you sit. And you’re continually discovering what your life is. And then you have this layer at which you’re telling yourself a story that you already know what your life is. And you know exactly who you should be and what’s about to happen, or you’re struggling to form a confident opinion about all of that. And yet there is this fundamental mystery to everything, even the most familiar experience.
Lex Fridman (04:24:20):
We’re all NPCs in a most marvelous video game.
Sam Harris (04:24:26):
Maybe, although my game, my sense of gaming does not run as deep as to know what I’m committing to there. It’s a non-playing character.
Lex Fridman (04:24:33):
You’re more of a Mario Kart guy, I can tell.
Sam Harris (04:24:37):
I went back, I was an original video gamer, but it’s been a long time since I, I mean, I was there for Pong. I remember when I saw the first Pong in a restaurant in, I think it was like Benihana’s or something, they had a Pong table, and that was just,
Lex Fridman (04:24:53):
that was an amazing moment. You, Sam Harris, might live from Pong to the invention and deployment of a super-intelligent system.
Sam Harris (04:25:03):
Yeah, well, that happened fast, if it happens any time in my lifetime.
Lex Fridman (04:25:06):
From Pong to AGI. What kind of things do you do purely for fun that others might consider a waste of time?
Sam Harris (04:25:15):
Purely for fun?
Lex Fridman (04:25:18):
Because meditation doesn’t count, because most people would say that’s not a waste of time. Is there something like Pong that’s a deeply embarrassing thing you would never admit?
Sam Harris (04:25:30):
I don’t think, well, I mean, once or twice a year, I will play a round of golf, which many people would find embarrassing. They might even find my play embarrassing, but it’s fun. Do you find it embarrassing? No, I mean, I love, golf just takes way too much time, so I can only squander a certain amount of time on it. But I do love it, it’s a lot of fun.
Lex Fridman (04:25:48):
Well, you have no control over your actual performance.
Sam Harris (04:25:51):
You’re ever-discovering. I do have control over my mediocre performance, but I don’t have enough control as to make it really good. But happily, I’m in the perfect spot, because I don’t invest enough time in it to care how I play, so I just have fun when I play.
Lex Fridman (04:26:07):
Well, I hope there’ll be a day where you play a round of golf with the former president of Donald Trump,
Sam Harris (04:26:13):
and I would love to be- I would bet on him if we played golf. I’m sure he’s a better golfer.
Lex Fridman (04:26:18):
Amidst the chaos of human civilization in modern times, as we’ve talked about, what gives you hope about this world in the coming year, in the coming decade, in the coming hundred years, maybe a thousand years? What’s the source of hope for you?
Sam Harris (04:26:37):
Well, it comes back to a few of the things we’ve talked about. I mean, I think I’m hopeful. I know that most people are good and are mostly converging on the same core values, right? It’s like we’re not surrounded by psychopaths, and the thing that finally convinced me to get off Twitter was how different life was seeming through the lens of Twitter. It’s like, I just got the sense that there are way more psychopaths, or effective psychopaths, than I realized, and then I thought, okay, this isn’t real. This is either a strange context in which actually decent people are behaving like psychopaths or it’s a bot army or something that I don’t have to take seriously. So, yeah, I just think most people, if we can get the incentives right, I think there’s no reason why we can’t really thrive collectively. Like, there’s enough wealth to go around, there’s enough, you know, there’s no effective limit, you know, I mean, within the limits of what’s physically possible, but we’re nowhere near the limit on abundance. You know, on this, forget about going to Mars, on this, the one rock, right? It’s like we could make this place incredibly beautiful and stable if we just did enough work to solve some, you know, rather long-standing political problems, you know.
Lex Fridman (04:28:23):
The problem of incentives. So, to you, the basic characteristics of human nature are such that we’ll be okay if the incentives are okay. We’ll do pretty good.
Sam Harris (04:28:35):
I’m worried about the asymmetries, that it’s easier to break things than to fix them, it’s easier to light a fire than to put it out, and I do worry that, you know, as technology gets more and more powerful, it becomes easier for the minority who wants to screw things up to effectively screw things up for everybody, right? So, it’s easier, it’s like a thousand years ago, it was simply impossible for one person to range the lives of millions, much less billions. Now that’s getting to be possible. So, on the assumption that we’re always gonna have a sufficient number of crazy individuals or malevolent individuals, it’s, we have to figure out that asymmetry somehow, and so there’s some cautious exploration of emergent technology that we need to get our heads screwed on straight about. And so, like, so gain-of-function research, like just how much do we wanna democratize, you know, all the relevant technologies there? You know, do we want really, you really wanna give everyone the ability to order nucleotides in the mail and give them the blueprints for viruses online because of, you know, you’re a free speech absolutist and you think all PDFs need to be, you know, exportable everywhere?
(04:30:06):
So, I’m much more, so this is where, yeah, so there are limits to, many people are confused about my take on free speech because I’ve come down on the unpopular side of some of these questions, but it’s been, my overriding concern is that in many cases I’m worried about the free speech of individual businesses or individual platforms or individual media people to decide that they don’t wanna be associated with certain things, right? So, like, if you own Twitter, I think you should be able to kick off the Nazi you don’t wanna be associated with because it’s your platform, you own it, right? That’s your free speech, right? That’s the side of my free speech concern for Twitter, right? It’s not that every Nazi has the right to be, to algorithmic speech on Twitter. I think if you own Twitter, you should, you or the, you know, whether it’s just Elon or, you know, in the world where it wasn’t Elon, just the people who own Twitter, and the board and the shareholders and the employees, these people need to, should be free to decide what they wanna promote or not. I view them as publishers more, you know, more than as platforms in the end and that has other implications. But I do worry about this problem of misinformation and algorithmically and otherwise, you know, supercharged misinformation.
(04:31:31):
And I think, I do think we have, we’re at a bottleneck now. I mean, I guess it could be the hubris of every present generation to think that their moment is especially important. But I do think with the emergence of these technologies, we’re at some kind of bottleneck where we really have to figure out how to get this right. And if we do get this right, if we figure out how to not drive ourselves crazy by giving people access to all possible information and misinformation at all times, I think, yeah, we could, there’s no limit to how happily we could collaborate with billions of creative, fulfilled people.
Lex Fridman (04:32:12):
You know, it’s just. And trillions of robots, some of them sex robots,
Sam Harris (04:32:17):
but that’s another topic. Robots that are running the right algorithm, whatever that algorithm is.
Lex Fridman (04:32:22):
Whatever you need in your life to make you happy. Sam, the first time we talked is, one of the huge honors of my life, I’ve been a fan of yours for a long time. The few times you were respectful, but critical to me means the world. And thank you so much for helping me and caring enough about the world and for everything you do. But I should say that the few of us that try to put love in the world on Twitter miss you on Twitter, but. Well, enjoy yourselves. Yeah.
Sam Harris (04:32:54):
Don’t break anything, kids. Have a good party without me. Thanks so much. I’m very happy to do this. Thanks for the invitation. Thank you.
Lex Fridman (04:33:03):
Great to see you again. Thanks for listening to this conversation with Sam Harris. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Martin Luther King Jr. Love is the only force capable of transforming an enemy into a friend. Thank you for listening. And hope to see you next time.
Sam Harris is an author, podcaster, and philosopher. Please support this podcast by checking out our sponsors:
– Notion: https://notion.com
– Indeed: https://indeed.com/lex to get $75 credit
– MasterClass: https://masterclass.com/lex to get 15% off
EPISODE LINKS:
Sam’s Website: https://samharris.org
Making Sense Podcast: https://www.samharris.org/podcasts/making-sense-episodes
Waking Up App: https://www.wakingup.com
Sam’s YouTube: https://youtube.com/@samharrisorg
Sam’s Instagram: https://instagram.com/samharrisorg
PODCAST INFO:
Podcast website: https://lexfridman.com/podcast
Apple Podcasts: https://apple.co/2lwqZIr
Spotify: https://spoti.fi/2nEwCF8
RSS: https://lexfridman.com/feed/podcast/
YouTube Full Episodes: https://youtube.com/lexfridman
YouTube Clips: https://youtube.com/lexclips
SUPPORT & CONNECT:
– Check out the sponsors above, it’s the best way to support this podcast
– Support on Patreon: https://www.patreon.com/lexfridman
– Twitter: https://twitter.com/lexfridman
– Instagram: https://www.instagram.com/lexfridman
– LinkedIn: https://www.linkedin.com/in/lexfridman
– Facebook: https://www.facebook.com/lexfridman
– Medium: https://medium.com/@lexfridman
OUTLINE:
Here’s the timestamps for the episode. On some podcast players you should be able to click the timestamp to jump to that time.
(00:00) – Introduction
(09:25) – Empathy and reason
(17:17) – Donald Trump
(1:00:11) – Military industrial complex
(1:04:45) – Twitter
(1:28:52) – COVID
(2:12:35) – Kanye West
(2:29:11) – Platforming
(2:47:07) – Joe Rogan
(3:03:59) – Bret Weinstein
(3:17:38) – Elon Musk
(3:29:45) – Artificial Intelligence
(3:45:48) – UFOs
(3:59:03) – Free will
(4:26:17) – Hope for the future
Podscript is a personal project to make podcast transcripts available to everyone for free. Please support this project by following us on Twitter.